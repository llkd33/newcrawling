#!/usr/bin/env python3
"""
ÎÑ§Ïù¥Î≤Ñ Ïπ¥Ìéò ÌÅ¨Î°§ÎßÅ -> ÎÖ∏ÏÖò Ï†ÄÏû• Î©îÏù∏ Ïä§ÌÅ¨Î¶ΩÌä∏
Îß§Ïùº Ï†ïÍ∏∞Ï†ÅÏúºÎ°ú Ïã§ÌñâÎêòÏñ¥ ÏÉà Í≤åÏãúÎ¨ºÏùÑ ÌÅ¨Î°§ÎßÅÌïòÍ≥† ÎÖ∏ÏÖòÏóê Ï†ÄÏû•
"""

import os
import sys
import json
import time
import logging
from datetime import datetime, timedelta
from typing import List, Dict
from dotenv import load_dotenv
import hashlib

# Selenium imports
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service

# Notion imports
from notion_client import Client

# ÌôòÍ≤ΩÎ≥ÄÏàò Î°úÎìú
load_dotenv()

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('crawler.log', encoding='utf-8')
    ]
)

class NaverCafeCrawler:
    """ÎÑ§Ïù¥Î≤Ñ Ïπ¥Ìéò ÌÅ¨Î°§Îü¨"""
    
    def __init__(self):
        self.driver = None
        self.wait = None
        self.setup_driver()
        
    def setup_driver(self):
        """Selenium ÎìúÎùºÏù¥Î≤Ñ ÏÑ§Ï†ï"""
        options = Options()
        
        # GitHub Actions ÌôòÍ≤ΩÏóêÏÑúÎäî Ìó§ÎìúÎ¶¨Ïä§ Î™®Îìú ÌïÑÏàò
        if os.getenv('GITHUB_ACTIONS'):
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
        
        # Í∏∞Î≥∏ ÏòµÏÖò
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        try:
            self.driver = webdriver.Chrome(options=options)
            self.wait = WebDriverWait(self.driver, 10)
            logging.info("‚úÖ ÌÅ¨Î°¨ ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî ÏÑ±Í≥µ")
        except Exception as e:
            logging.error(f"‚ùå ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            raise
    
    def login_naver(self):
        """ÎÑ§Ïù¥Î≤Ñ Î°úÍ∑∏Ïù∏"""
        try:
            self.driver.get('https://nid.naver.com/nidlogin.login')
            time.sleep(2)
            
            # ID ÏûÖÎ†•
            id_input = self.driver.find_element(By.ID, 'id')
            id_input.send_keys(os.getenv('NAVER_ID'))
            time.sleep(1)
            
            # PW ÏûÖÎ†•
            pw_input = self.driver.find_element(By.ID, 'pw')
            pw_input.send_keys(os.getenv('NAVER_PW'))
            time.sleep(1)
            
            # Î°úÍ∑∏Ïù∏ Î≤ÑÌäº ÌÅ¥Î¶≠
            login_btn = self.driver.find_element(By.ID, 'log.login')
            login_btn.click()
            time.sleep(5)  # Î°úÍ∑∏Ïù∏ ÎåÄÍ∏∞ ÏãúÍ∞Ñ Ï¶ùÍ∞Ä
            
            logging.info("‚úÖ ÎÑ§Ïù¥Î≤Ñ Î°úÍ∑∏Ïù∏ ÏÑ±Í≥µ")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå Î°úÍ∑∏Ïù∏ Ïã§Ìå®: {e}")
            return False
    
    def crawl_cafe(self, cafe_config: Dict) -> List[Dict]:
        """Ïπ¥Ìéò Í≤åÏãúÎ¨º ÌÅ¨Î°§ÎßÅ"""
        results = []
        
        try:
            # URL Í≤ÄÏ¶ù
            if not cafe_config.get('url') or not cafe_config.get('club_id') or not cafe_config.get('board_id'):
                logging.error(f"Ïπ¥Ìéò ÏÑ§Ï†ïÏù¥ Ïò¨Î∞îÎ•¥ÏßÄ ÏïäÏäµÎãàÎã§: {cafe_config}")
                return results
            
            # Ïπ¥Ìéò Í≤åÏãúÌåê URLÎ°ú Ïù¥Îèô
            board_url = f"{cafe_config['url']}/ArticleList.nhn?search.clubid={cafe_config['club_id']}&search.menuid={cafe_config['board_id']}"
            logging.info(f"üìç URL Ï†ëÏÜç: {board_url}")
            self.driver.get(board_url)
            time.sleep(3)
            
            # iframe Ï†ÑÌôò
            try:
                self.driver.switch_to.frame('cafe_main')
                time.sleep(1)
            except:
                logging.warning("iframe Ï†ÑÌôò Ïã§Ìå®, ÏßÅÏ†ë Ï†ëÍ∑º ÏãúÎèÑ")
            
            # Ïó¨Îü¨ ÏÑ†ÌÉùÏûê ÏãúÎèÑ (ÎÑ§Ïù¥Î≤Ñ Ïπ¥Ìéò Íµ¨Ï°∞Í∞Ä Îã§ÏñëÌï®)
            selectors = [
                'div.article-board table tbody tr',  # Íµ¨Ìòï Ïπ¥Ìéò
                'ul.article-movie-sub li',  # ÏòÅÌôîÌòï
                'div.ArticleListItem',  # ÏÉàÌòï Ïπ¥Ìéò
                'tr[class*="board-list"]',  # ÏùºÎ∞ò Î¶¨Ïä§Ìä∏
                'div.inner_list > a'  # Î™®Î∞îÏùºÌòï
            ]
            
            articles = []
            for selector in selectors:
                try:
                    articles = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if articles:
                        logging.info(f"‚úÖ Í≤åÏãúÎ¨º Î∞úÍ≤¨: {selector} ({len(articles)}Í∞ú)")
                        break
                except:
                    continue
            
            if not articles:
                logging.warning("‚ùå Í≤åÏãúÎ¨ºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. HTML Íµ¨Ï°∞ ÌôïÏù∏ ÌïÑÏöî")
                # HTML ÎîîÎ≤ÑÍπÖ Ï†ïÎ≥¥
                try:
                    page_source = self.driver.page_source[:500]
                    logging.debug(f"Page HTML: {page_source}")
                except:
                    pass
                return results
            
            # Ïã§Ï†ú Í≤åÏãúÎ¨ºÎßå ÌïÑÌÑ∞ÎßÅ (Í≥µÏßÄÏÇ¨Ìï≠ Ï†úÏô∏)
            actual_articles = []
            for article in articles:
                try:
                    # Í≥µÏßÄÏÇ¨Ìï≠ ÌÅ¥ÎûòÏä§ Ï≤¥ÌÅ¨
                    class_attr = article.get_attribute('class') or ''
                    if 'notice' in class_attr.lower() or 'Í≥µÏßÄ' in class_attr:
                        continue
                    # Îπà Ìñâ Ï†úÏô∏
                    if not article.text.strip():
                        continue
                    actual_articles.append(article)
                except:
                    actual_articles.append(article)
            
            logging.info(f"üìä Í≥µÏßÄ Ï†úÏô∏ Ïã§Ï†ú Í≤åÏãúÎ¨º: {len(actual_articles)}Í∞ú")
            
            # ÏµúÎåÄ 4Í∞úÏî©Îßå Ï≤òÎ¶¨
            max_articles = 4
            processed_count = 0
            new_articles_found = 0
            
            # Îçî ÎßéÏùÄ Í≤åÏãúÎ¨º ÌôïÏù∏ (ÏÉà Í≤åÏãúÎ¨º 4Í∞ú Ï∞æÏùÑ ÎïåÍπåÏßÄ)
            for idx, article in enumerate(actual_articles[:20], 1):  # ÏµúÏã† 20Í∞ú ÌôïÏù∏
                if processed_count >= max_articles:
                    logging.info(f"‚úÖ ÏµúÎåÄ Ï≤òÎ¶¨ Í∞úÏàò({max_articles}Í∞ú) ÎèÑÎã¨")
                    break
                    
                try:
                    logging.debug(f"Ï≤òÎ¶¨ Ï§ë: {processed_count + 1}/{max_articles}")
                    
                    # Ï†úÎ™© Ï∞æÍ∏∞ (Ïó¨Îü¨ Î∞©Î≤ï ÏãúÎèÑ)
                    title = ""
                    link = ""
                    
                    # Î∞©Î≤ï 1: a.article
                    try:
                        title_elem = article.find_element(By.CSS_SELECTOR, 'a.article')
                        title = title_elem.text.strip()
                        link = title_elem.get_attribute('href')
                    except:
                        pass
                    
                    # Î∞©Î≤ï 2: td.td_article
                    if not title:
                        try:
                            title_elem = article.find_element(By.CSS_SELECTOR, 'td.td_article a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            pass
                    
                    # Î∞©Î≤ï 3: class="inner_list"
                    if not title:
                        try:
                            title_elem = article.find_element(By.CSS_SELECTOR, '.inner_list a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            pass
                    
                    # Î∞©Î≤ï 4: ÏßÅÏ†ë a ÌÉúÍ∑∏
                    if not title:
                        try:
                            title_elem = article.find_element(By.TAG_NAME, 'a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            continue
                    
                    if not title or not link:
                        continue
                    
                    # Í≥µÏßÄÏÇ¨Ìï≠ Ï†úÏô∏
                    if 'Í≥µÏßÄ' in title or 'notice' in str(article.get_attribute('class')):
                        continue
                    
                    # ÏûëÏÑ±Ïûê
                    author = "Unknown"
                    for author_selector in ['td.td_name a', '.td_name', '.nick', '.p-nick']:
                        try:
                            author = article.find_element(By.CSS_SELECTOR, author_selector).text.strip()
                            if author:
                                break
                        except:
                            pass
                    
                    # ÏûëÏÑ±Ïùº
                    date_str = ""
                    for date_selector in ['td.td_date', '.td_date', '.date']:
                        try:
                            date_str = article.find_element(By.CSS_SELECTOR, date_selector).text.strip()
                            if date_str:
                                break
                        except:
                            pass
                    
                    # ÎÇ†Ïßú ÌòïÏãù Î≥ÄÌôò (YYYY.MM.DD. ‚Üí YYYY-MM-DD)
                    if date_str:
                        # "2025.08.25." ÌòïÏãùÏùÑ "2025-08-25"Î°ú Î≥ÄÌôò
                        date_str = date_str.replace('.', '-').rstrip('-')
                        if len(date_str.split('-')) == 3:
                            year, month, day = date_str.split('-')
                            # 2ÏûêÎ¶¨ Ïó∞ÎèÑ Ï≤òÎ¶¨
                            if len(year) == 2:
                                year = '20' + year
                            date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                        else:
                            date = datetime.now().strftime('%Y-%m-%d')
                    else:
                        date = datetime.now().strftime('%Y-%m-%d')
                    
                    # Ï°∞ÌöåÏàò
                    views = "0"
                    for view_selector in ['td.td_view', '.td_view', '.view']:
                        try:
                            views = article.find_element(By.CSS_SELECTOR, view_selector).text.strip()
                            if views:
                                break
                        except:
                            pass
                    
                    # Í≤åÏãúÎ¨º ID Ï∂îÏ∂ú
                    article_id = link.split('articleid=')[-1].split('&')[0] if 'articleid=' in link else ""
                    
                    # URLÎ°ú Ï§ëÎ≥µ Ï≤¥ÌÅ¨ (ÌÅ¨Î°§ÎßÅ Ï†ÑÏóê ÌôïÏù∏)
                    if link:
                        # Ïù¥ÎØ∏ ÎÖ∏ÏÖòÏóê ÏûàÎäîÏßÄ Î®ºÏ†Ä Ï≤¥ÌÅ¨
                        try:
                            notion_check = NotionDatabase()
                            if notion_check.check_duplicate(link):
                                logging.info(f"‚è≠Ô∏è [{idx:02d}] Ïù¥ÎØ∏ Ï†ÄÏû•Îêú Í≤åÏãúÎ¨º: {title[:30]}...")
                                continue
                            else:
                                new_articles_found += 1
                                logging.info(f"‚ú® [{new_articles_found:02d}] ÏÉà Í≤åÏãúÎ¨º Î∞úÍ≤¨: {title[:30]}...")
                        except Exception as e:
                            logging.debug(f"Ï§ëÎ≥µ Ï≤¥ÌÅ¨ Ï§ë Ïò§Î•ò: {e}")
                            # Ïò§Î•ò ÏãúÏóêÎèÑ Í≥ÑÏÜç ÏßÑÌñâ
                            new_articles_found += 1
                    
                    # ÏÉÅÏÑ∏ ÎÇ¥Ïö© ÌÅ¨Î°§ÎßÅ
                    logging.info(f"üìñ ÎÇ¥Ïö© ÌÅ¨Î°§ÎßÅ Ï§ë: {title[:30]}...")
                    content = self.get_article_content(link)
                    logging.info(f"üìù ÎÇ¥Ïö© Í∏∏Ïù¥: {len(content)} Í∏ÄÏûê")
                    
                    # Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ±
                    data = {
                        'title': title,
                        'author': author,
                        'date': date,
                        'views': views,
                        'url': link,
                        'article_id': article_id,
                        'content': content,
                        'cafe_name': cafe_config['name'],
                        'board_name': cafe_config['board_name'],
                        'crawled_at': datetime.now().isoformat(),
                        'hash': hashlib.md5(f"{title}{link}".encode()).hexdigest()
                    }
                    
                    # ÎîîÎ≤ÑÍπÖ Ï†ïÎ≥¥
                    logging.debug(f"Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ± ÏôÑÎ£å:")
                    logging.debug(f"  - Ï†úÎ™©: {data['title'][:50]}")
                    logging.debug(f"  - ÎÇ¥Ïö©: {data['content'][:100]}...")
                    
                    results.append(data)
                    processed_count += 1
                    logging.info(f"üìÑ [{processed_count:02d}/{max_articles}] ÌÅ¨Î°§ÎßÅ: {title[:30]}...")
                    
                    # ÏöîÏ≤≠ Í∞ÑÍ≤©
                    time.sleep(1)
                    
                except Exception as e:
                    logging.error(f"Í≤åÏãúÎ¨º ÌÅ¨Î°§ÎßÅ Ïò§Î•ò: {e}")
                    continue
            
            self.driver.switch_to.default_content()
            
        except Exception as e:
            logging.error(f"Ïπ¥Ìéò ÌÅ¨Î°§ÎßÅ Ïò§Î•ò: {e}")
        
        return results
    
    def get_article_content(self, url: str) -> str:
        """Í≤åÏãúÎ¨º ÏÉÅÏÑ∏ ÎÇ¥Ïö© Í∞ÄÏ†∏Ïò§Í∏∞"""
        content = ""
        
        try:
            # ÌòÑÏû¨ Ï∞Ω Ìï∏Îì§ Ï†ÄÏû•
            original_window = self.driver.current_window_handle
            
            # ÏÉà ÌÉ≠ÏóêÏÑú Í≤åÏãúÎ¨º Ïó¥Í∏∞
            self.driver.execute_script(f"window.open('{url}', '_blank');")
            self.driver.switch_to.window(self.driver.window_handles[-1])
            
            # ÌéòÏù¥ÏßÄ ÏôÑÏ†ÑÌûà Î°úÎî© ÎåÄÍ∏∞
            time.sleep(5)
            
            # iframeÏúºÎ°ú Ï†ÑÌôò (ÎÑ§Ïù¥Î≤Ñ Ïπ¥ÌéòÎäî iframe ÏÇ¨Ïö©)
            try:
                self.driver.switch_to.frame('cafe_main')
                logging.info("‚úÖ iframe Ï†ÑÌôò ÏÑ±Í≥µ")
                
                # Ïä§ÌÅ¨Î¶ΩÌä∏Î°ú ÏßÅÏ†ë ÎÇ¥Ïö© Í∞ÄÏ†∏Ïò§Í∏∞ ÏãúÎèÑ
                try:
                    # Î∞©Î≤ï 1: Ïä§ÎßàÌä∏ÏóêÎîîÌÑ∞ ONE (ÏµúÏã†)
                    content = self.driver.execute_script("""
                        var elem = document.querySelector('.se-main-container');
                        if (elem) return elem.innerText;
                        return '';
                    """)
                    
                    if content and len(content) > 30:
                        logging.info(f"‚úÖ Ïä§ÎßàÌä∏ÏóêÎîîÌÑ∞ ONEÏóêÏÑú ÎÇ¥Ïö© Ï∂îÏ∂ú: {len(content)}Ïûê")
                        self.driver.close()
                        self.driver.switch_to.window(original_window)
                        return content[:2000]
                    
                    # Î∞©Î≤ï 2: ContentRenderer (ÏÉà Î†åÎçîÎü¨)
                    content = self.driver.execute_script("""
                        var elem = document.querySelector('.ContentRenderer');
                        if (elem) return elem.innerText;
                        return '';
                    """)
                    
                    if content and len(content) > 30:
                        logging.info(f"‚úÖ ContentRendererÏóêÏÑú ÎÇ¥Ïö© Ï∂îÏ∂ú: {len(content)}Ïûê")
                        self.driver.close()
                        self.driver.switch_to.window(original_window)
                        return content[:2000]
                    
                    # Î∞©Î≤ï 3: ÏùºÎ∞ò Í≤åÏãúÍ∏Ä ÏòÅÏó≠
                    content = self.driver.execute_script("""
                        var selectors = [
                            '#postViewArea',
                            '#content-area',
                            '.post_ct',
                            '#tbody',
                            '.NHN_Writeform_Main',
                            'div[class*="view_content"]',
                            '.article_viewer',
                            '.board-view-content'
                        ];
                        
                        for (var i = 0; i < selectors.length; i++) {
                            var elem = document.querySelector(selectors[i]);
                            if (elem && elem.innerText && elem.innerText.length > 30) {
                                return elem.innerText;
                            }
                        }
                        return '';
                    """)
                    
                    if content and len(content) > 30:
                        logging.info(f"‚úÖ ÏùºÎ∞ò ÏÑ†ÌÉùÏûêÏóêÏÑú ÎÇ¥Ïö© Ï∂îÏ∂ú: {len(content)}Ïûê")
                        self.driver.close()
                        self.driver.switch_to.window(original_window)
                        return content[:2000]
                    
                    # Î∞©Î≤ï 4: Î™®Îì† ÌÖçÏä§Ìä∏ ÎÖ∏Îìú ÏàòÏßë
                    content = self.driver.execute_script("""
                        // Ï†úÎ™©, ÏûëÏÑ±Ïûê Ï†ïÎ≥¥ Îì±ÏùÑ Ï†úÏô∏Ìïú Î≥∏Î¨∏Îßå Ï∂îÏ∂ú
                        var bodyArea = document.querySelector('td.view, div.view_content, div#content-area');
                        if (bodyArea) {
                            // Î∂àÌïÑÏöîÌïú ÏöîÏÜå Ï†úÍ±∞
                            var removes = bodyArea.querySelectorAll('.reply, .comment, script, style');
                            removes.forEach(function(el) { el.remove(); });
                            return bodyArea.innerText;
                        }
                        
                        // Î™ª Ï∞æÏúºÎ©¥ body Ï†ÑÏ≤¥ÏóêÏÑú Í∏¥ ÌÖçÏä§Ìä∏ Ï∞æÍ∏∞
                        var allText = [];
                        var paragraphs = document.querySelectorAll('p, div');
                        for (var i = 0; i < paragraphs.length; i++) {
                            var text = paragraphs[i].innerText || '';
                            if (text.length > 100 && !text.includes('Î°úÍ∑∏Ïù∏') && !text.includes('Î©îÎâ¥')) {
                                allText.push(text);
                            }
                        }
                        return allText.join('\\n\\n');
                    """)
                    
                    if content and len(content) > 30:
                        logging.info(f"‚úÖ ÌÖçÏä§Ìä∏ ÎÖ∏Îìú ÏàòÏßëÏúºÎ°ú ÎÇ¥Ïö© Ï∂îÏ∂ú: {len(content)}Ïûê")
                        
                except Exception as js_error:
                    logging.error(f"JavaScript Ïã§Ìñâ Ïò§Î•ò: {js_error}")
                    
                    # JavaScript Ïã§Ìå® Ïãú Í∏∞Ï°¥ Î∞©Î≤ïÏúºÎ°ú ÏãúÎèÑ
                    selectors = [
                        'div.se-main-container',
                        'div.ContentRenderer', 
                        '#postViewArea',
                        '#content-area',
                        'td.view',
                        '#tbody'
                    ]
                    
                    for selector in selectors:
                        try:
                            elem = self.driver.find_element(By.CSS_SELECTOR, selector)
                            content = elem.text.strip()
                            if content and len(content) > 30:
                                logging.info(f"‚úÖ SeleniumÏúºÎ°ú ÎÇ¥Ïö© Ï∂îÏ∂ú: {selector} ({len(content)}Ïûê)")
                                break
                        except:
                            continue
                
            except Exception as iframe_error:
                logging.error(f"iframe Ï≤òÎ¶¨ Ïò§Î•ò: {iframe_error}")
                # iframe ÏóÜÏù¥ ÏãúÎèÑ
                content = self.driver.execute_script("return document.body.innerText;")
            
            # ÌÉ≠ Îã´Í∏∞
            self.driver.close()
            self.driver.switch_to.window(original_window)
            
            # ÎÇ¥Ïö© Í≤ÄÏ¶ù
            if content and len(content) > 30:
                # Î∂àÌïÑÏöîÌïú Í≥µÎ∞± Ï†ïÎ¶¨
                content = '\n'.join(line.strip() for line in content.split('\n') if line.strip())
                return content[:2000]
            else:
                logging.warning(f"ÎÇ¥Ïö© Ï∂îÏ∂ú Ïã§Ìå® - URL: {url}")
                return ""
                
        except Exception as e:
            logging.error(f"Í≤åÏãúÎ¨º ÎÇ¥Ïö© ÌÅ¨Î°§ÎßÅ Ïã§Ìå®: {e}")
            try:
                self.driver.close()
                self.driver.switch_to.window(self.driver.window_handles[0])
            except:
                pass
            return ""
    
    def close(self):
        """ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å"""
        if self.driver:
            self.driver.quit()
            logging.info("‚úÖ ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å")


class NotionDatabase:
    """ÎÖ∏ÏÖò Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ìï∏Îì§Îü¨"""
    
    def __init__(self):
        self.client = Client(auth=os.getenv('NOTION_TOKEN'))
        self.database_id = os.getenv('NOTION_DATABASE_ID')
    
    def check_duplicate(self, url: str) -> bool:
        """URLÎ°ú Ï§ëÎ≥µ Ï≤¥ÌÅ¨"""
        try:
            # URLÏóêÏÑú articleid Ï∂îÏ∂ú
            article_id = ""
            if 'articleid=' in url:
                article_id = url.split('articleid=')[1].split('&')[0]
            
            if article_id:
                # articleidÎ°ú Ï†ïÌôïÌïú Ï§ëÎ≥µ Ï≤¥ÌÅ¨
                response = self.client.databases.query(
                    database_id=self.database_id,
                    filter={
                        "property": "URL",
                        "url": {
                            "contains": f"articleid={article_id}"
                        }
                    }
                )
            else:
                # articleidÍ∞Ä ÏóÜÏúºÎ©¥ Ï†ÑÏ≤¥ URLÎ°ú Ï≤¥ÌÅ¨
                response = self.client.databases.query(
                    database_id=self.database_id,
                    filter={
                        "property": "URL",
                        "url": {
                            "equals": url
                        }
                    }
                )
            
            is_duplicate = len(response['results']) > 0
            if is_duplicate:
                logging.debug(f"Ï§ëÎ≥µ ÌôïÏù∏: {url[:50]}...")
            return is_duplicate
            
        except Exception as e:
            logging.debug(f"Ï§ëÎ≥µ Ï≤¥ÌÅ¨ Ïã§Ìå®: {e}")
            return False
    
    def save_article(self, article: Dict) -> bool:
        """Í≤åÏãúÎ¨º Ï†ÄÏû•"""
        try:
            # URLÎ°ú Ï§ëÎ≥µ Ï≤¥ÌÅ¨
            if self.check_duplicate(article['url']):
                logging.info(f"‚è≠Ô∏è Ï§ëÎ≥µ Í≤åÏãúÎ¨º Í±¥ÎÑàÎõ∞Í∏∞: {article['title'][:30]}...")
                return False
            
            # ÎÖ∏ÏÖò DBÏùò Ïã§Ï†ú ÌïÑÎìúÏóê ÎßûÏ∂∞ÏÑú Ï†ÄÏû•
            # ÌïÑÎìú ÌÉÄÏûÖÏùÑ Ï†ïÌôïÌûà ÎßûÏ∂∞Ïïº Ìï®
            properties = {}
            
            # Ï†úÎ™© ÌïÑÎìú - ÌôòÍ≤ΩÎ≥ÄÏàòÎ°ú ÏÑ§Ï†ï Í∞ÄÎä•, Í∏∞Î≥∏Í∞íÏùÄ "ÏÉà ÌéòÏù¥ÏßÄ"
            # ÎÖ∏ÏÖòÏùò Í∏∞Î≥∏ Title ÌïÑÎìúÎ™ÖÏùÄ Ïñ∏Ïñ¥ ÏÑ§Ï†ïÏóê Îî∞Îùº Îã§Î¶Ñ
            title_field = os.getenv('NOTION_TITLE_FIELD', 'ÏÉà ÌéòÏù¥ÏßÄ')
            
            # Ï†úÎ™©Ïù¥ ÎπÑÏñ¥ÏûàÏßÄ ÏïäÎèÑÎ°ù ÌôïÏù∏
            title_text = article.get('title', '').strip()
            if not title_text:
                title_text = f"Í≤åÏãúÎ¨º - {datetime.now().strftime('%Y%m%d%H%M%S')}"
            
            logging.info(f"üìù ÎÖ∏ÏÖò Ï†ÄÏû• ÏãúÏûë: Ï†úÎ™©={title_text[:30]}...")
            logging.debug(f"üìÑ ÎÇ¥Ïö© ÎØ∏Î¶¨Î≥¥Í∏∞: {article.get('content', '')[:100]}...")
            
            # Í∞ÄÎä•Ìïú Title ÌïÑÎìúÎ™ÖÎì§ ÏãúÎèÑ
            title_fields_to_try = [title_field, 'ÏÉà ÌéòÏù¥ÏßÄ', 'Name', 'Ïù¥Î¶Ñ', 'Ï†úÎ™©', 'Title']
            title_set = False
            
            for field_name in title_fields_to_try:
                try:
                    properties[field_name] = {
                        "title": [{"text": {"content": title_text}}]
                    }
                    title_set = True
                    logging.debug(f"Ï†úÎ™© ÌïÑÎìú ÏÑ§Ï†ï ÏÑ±Í≥µ: {field_name}")
                    break
                except:
                    continue
            
            if not title_set:
                logging.error("Ï†úÎ™© ÌïÑÎìúÎ•º ÏÑ§Ï†ïÌï† Ïàò ÏóÜÏäµÎãàÎã§")
            
            # URL ÌïÑÎìú
            if article.get('url'):
                properties["URL"] = {
                    "url": article['url']
                }
            
            # ÏûëÏÑ±Ïûê (Rich Text)
            if article.get('author'):
                properties["ÏûëÏÑ±Ïûê"] = {
                    "rich_text": [{"text": {"content": article['author']}}]
                }
            
            # ÏûëÏÑ±Ïùº (Rich TextÎ°ú Î≥ÄÍ≤Ω - ÏóêÎü¨ Î©îÏãúÏßÄÏóê Îî∞Îùº)
            if article.get('date'):
                properties["ÏûëÏÑ±Ïùº"] = {
                    "rich_text": [{"text": {"content": article['date']}}]
                }
            
            # Ïπ¥ÌéòÎ™Ö (Select)
            if article.get('cafe_name'):
                try:
                    properties["Ïπ¥ÌéòÎ™Ö"] = {
                        "select": {"name": article['cafe_name']}
                    }
                except:
                    # Select ÌïÑÎìúÍ∞Ä ÏóÜÏúºÎ©¥ ÌÖçÏä§Ìä∏Î°ú
                    properties["Ïπ¥ÌéòÎ™Ö"] = {
                        "rich_text": [{"text": {"content": article['cafe_name']}}]
                    }
            
            # ÎÇ¥Ïö© (Rich Text)
            content = article.get('content', '').strip()
            if not content:
                # ÎÇ¥Ïö©Ïù¥ ÎπÑÏñ¥ÏûàÏúºÎ©¥ Îã§Ïãú ÏãúÎèÑÌïòÏßÄ ÏïäÍ≥† Îπà Í∞íÏúºÎ°ú Ï≤òÎ¶¨
                content = "(ÎÇ¥Ïö©ÏùÑ Î∂àÎü¨Ïò§Îäî Ï§ë...)"
                logging.warning(f"ÎÇ¥Ïö©Ïù¥ ÎπÑÏñ¥ÏûàÏùå: {title_text}")
            
            # ÎÖ∏ÏÖò Rich Text Ï†úÌïú (2000Ïûê)
            content = content[:2000]
            
            # ÎÇ¥Ïö© ÌïÑÎìú ÏÑ§Ï†ï
            properties["ÎÇ¥Ïö©"] = {
                "rich_text": [{"text": {"content": content}}]
            }
            
            # ÌÅ¨Î°§ÎßÅ ÏùºÏãú (Date)
            try:
                properties["ÌÅ¨Î°§ÎßÅ ÏùºÏãú"] = {
                    "date": {"start": datetime.now().isoformat()}
                }
            except:
                # Date ÌïÑÎìúÍ∞Ä ÏóÜÏúºÎ©¥ ÌÖçÏä§Ìä∏Î°ú
                properties["ÌÅ¨Î°§ÎßÅ ÏùºÏãú"] = {
                    "rich_text": [{"text": {"content": datetime.now().isoformat()}}]
                }
            
            # uploaded Ï≤¥ÌÅ¨Î∞ïÏä§
            properties["uploaded"] = {
                "checkbox": False
            }
            
            # ÎÖ∏ÏÖò ÌéòÏù¥ÏßÄ ÏÉùÏÑ±
            page = self.client.pages.create(
                parent={"database_id": self.database_id},
                properties=properties
            )
            
            # ÌéòÏù¥ÏßÄ ÎÇ¥Ïö© Ï∂îÍ∞Ä (Î∏îÎ°ùÏúºÎ°ú)
            try:
                # ÌéòÏù¥ÏßÄ Î≥∏Î¨∏Ïóê ÏÉÅÏÑ∏ ÎÇ¥Ïö© Ï∂îÍ∞Ä
                blocks = []
                
                # Ï†úÎ™© Î∏îÎ°ù
                blocks.append({
                    "object": "block",
                    "type": "heading_1",
                    "heading_1": {
                        "rich_text": [{
                            "type": "text",
                            "text": {"content": title_text}
                        }]
                    }
                })
                
                # Ï†ïÎ≥¥ Î∏îÎ°ù
                blocks.append({
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{
                            "type": "text",
                            "text": {"content": f"üìÖ ÏûëÏÑ±Ïùº: {article.get('date', 'N/A')}\nüë§ ÏûëÏÑ±Ïûê: {article.get('author', 'Unknown')}\nüìä Ï°∞ÌöåÏàò: {article.get('views', '0')}"}
                        }]
                    }
                })
                
                # Íµ¨Î∂ÑÏÑ†
                blocks.append({
                    "object": "block",
                    "type": "divider",
                    "divider": {}
                })
                
                # Î≥∏Î¨∏ ÎÇ¥Ïö©
                if content and content != "ÎÇ¥Ïö©ÏùÑ Í∞ÄÏ†∏Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§.":
                    # ÎÇ¥Ïö©ÏùÑ Îã®ÎùΩÏúºÎ°ú ÎÇòÎàÑÍ∏∞
                    paragraphs = content.split('\n\n')
                    for para in paragraphs[:10]:  # ÏµúÎåÄ 10Í∞ú Îã®ÎùΩ
                        if para.strip():
                            blocks.append({
                                "object": "block",
                                "type": "paragraph",
                                "paragraph": {
                                    "rich_text": [{
                                        "type": "text",
                                        "text": {"content": para.strip()[:2000]}
                                    }]
                                }
                            })
                
                # ÏõêÎ≥∏ ÎßÅÌÅ¨
                blocks.append({
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{
                            "type": "text",
                            "text": {
                                "content": "üîó ÏõêÎ≥∏ Í≤åÏãúÎ¨º Î≥¥Í∏∞",
                                "link": {"url": article.get('url', '')}
                            }
                        }]
                    }
                })
                
                # Î∏îÎ°ù Ï∂îÍ∞Ä
                self.client.blocks.children.append(
                    block_id=page["id"],
                    children=blocks
                )
            except Exception as e:
                logging.debug(f"ÌéòÏù¥ÏßÄ ÎÇ¥Ïö© Ï∂îÍ∞Ä Ï§ë Ïò§Î•ò (Î¨¥Ïãú): {e}")
            
            logging.info(f"‚úÖ ÎÖ∏ÏÖò Ï†ÄÏû• ÏÑ±Í≥µ: {title_text[:30]}...")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå ÎÖ∏ÏÖò Ï†ÄÏû• Ïã§Ìå®: {e}")
            return False


def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    logging.info("="*60)
    logging.info("üöÄ ÎÑ§Ïù¥Î≤Ñ Ïπ¥Ìéò -> ÎÖ∏ÏÖò ÌÅ¨Î°§ÎßÅ ÏãúÏûë")
    logging.info(f"‚è∞ Ïã§Ìñâ ÏãúÍ∞Ñ: {datetime.now()}")
    logging.info("="*60)
    
    # ÌôòÍ≤ΩÎ≥ÄÏàò ÌôïÏù∏
    required_env = ['NAVER_ID', 'NAVER_PW', 'NOTION_TOKEN', 'NOTION_DATABASE_ID']
    missing_env = [env for env in required_env if not os.getenv(env)]
    
    if missing_env:
        logging.error(f"‚ùå ÌïÑÏàò ÌôòÍ≤ΩÎ≥ÄÏàòÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§: {', '.join(missing_env)}")
        logging.error("GitHub SecretsÎ•º ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî!")
        sys.exit(1)
    
    # Ïπ¥Ìéò ÏÑ§Ï†ï (2Í≥≥)
    cafes = []
    
    # Ïπ¥Ìéò 1 ÏÑ§Ï†ï ÌôïÏù∏
    if os.getenv('CAFE1_URL') and os.getenv('CAFE1_CLUB_ID') and os.getenv('CAFE1_BOARD_ID'):
        cafes.append({
            'name': os.getenv('CAFE1_NAME', 'Ïπ¥Ìéò1'),
            'url': os.getenv('CAFE1_URL'),
            'club_id': os.getenv('CAFE1_CLUB_ID'),
            'board_id': os.getenv('CAFE1_BOARD_ID'),
            'board_name': os.getenv('CAFE1_BOARD_NAME', 'Í≤åÏãúÌåê')
        })
    
    # Ïπ¥Ìéò 2 ÏÑ§Ï†ï ÌôïÏù∏
    if os.getenv('CAFE2_URL') and os.getenv('CAFE2_CLUB_ID') and os.getenv('CAFE2_BOARD_ID'):
        cafes.append({
            'name': os.getenv('CAFE2_NAME', 'Ïπ¥Ìéò2'),
            'url': os.getenv('CAFE2_URL'),
            'club_id': os.getenv('CAFE2_CLUB_ID'),
            'board_id': os.getenv('CAFE2_BOARD_ID'),
            'board_name': os.getenv('CAFE2_BOARD_NAME', 'Í≤åÏãúÌåê')
        })
    
    if not cafes:
        logging.error("‚ùå ÌÅ¨Î°§ÎßÅÌï† Ïπ¥ÌéòÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§!")
        logging.error("ÏµúÏÜå 1Í∞ú Ïù¥ÏÉÅÏùò Ïπ¥Ìéò Ï†ïÎ≥¥Î•º GitHub SecretsÏóê ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî:")
        logging.error("CAFE1_URL, CAFE1_CLUB_ID, CAFE1_BOARD_ID")
        sys.exit(1)
    
    # ÌÅ¨Î°§Îü¨ Ï¥àÍ∏∞Ìôî
    crawler = NaverCafeCrawler()
    notion = NotionDatabase()
    
    try:
        # ÎÑ§Ïù¥Î≤Ñ Î°úÍ∑∏Ïù∏
        if not crawler.login_naver():
            raise Exception("Î°úÍ∑∏Ïù∏ Ïã§Ìå®")
        
        total_saved = 0
        
        # Í∞Å Ïπ¥Ìéò ÌÅ¨Î°§ÎßÅ
        for cafe in cafes:
            logging.info(f"\nüìç {cafe['name']} ÌÅ¨Î°§ÎßÅ ÏãúÏûë...")
            articles = crawler.crawl_cafe(cafe)
            
            # ÎÖ∏ÏÖòÏóê Ï†ÄÏû•
            cafe_saved = 0
            for article in articles:
                if notion.save_article(article):
                    cafe_saved += 1
                    total_saved += 1
            
            logging.info(f"‚úÖ {cafe['name']}: {len(articles)}Í∞ú ÌÅ¨Î°§ÎßÅ, {cafe_saved}Í∞ú ÏÉàÎ°ú Ï†ÄÏû•")
            time.sleep(2)
        
        logging.info(f"\nüéâ ÌÅ¨Î°§ÎßÅ ÏôÑÎ£å! Ï¥ù {total_saved}Í∞ú ÏÉà Í≤åÏãúÎ¨º Ï†ÄÏû•")
        
    except Exception as e:
        logging.error(f"‚ùå ÌÅ¨Î°§ÎßÅ Ïã§Ìå®: {e}")
        sys.exit(1)
    
    finally:
        crawler.close()


if __name__ == "__main__":
    main()