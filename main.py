#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ë§ -> ë…¸ì…˜ ì €ì¥ (ìµœì¢… ìˆ˜ì • ë²„ì „)
ë‚´ìš© ì¶”ì¶œ ë¬¸ì œ ì™„ì „ í•´ê²°
"""

import os
import sys
import time
import logging
from datetime import datetime
import re
from typing import List, Dict
from dotenv import load_dotenv
import hashlib

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from notion_client import Client

# ìƒˆë¡œìš´ ì½˜í…ì¸  ì¶”ì¶œ ì‹œìŠ¤í…œ import
from content_extractor import ContentExtractor
from content_extraction_models import ExtractionConfig

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('crawler.log', encoding='utf-8')
    ]
)

class NaverCafeCrawler:
    """ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.driver = None
        self.wait = None
        self.content_extractor = None
        self.setup_driver()
        
    def setup_driver(self):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì •"""
        options = Options()
        
        # GitHub Actions í™˜ê²½
        if os.getenv('GITHUB_ACTIONS'):
            # Use new headless for better JS rendering in CI
            options.add_argument('--headless=new')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
        
        # ê¸°ë³¸ ì˜µì…˜
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        try:
            self.driver = webdriver.Chrome(options=options)
            self.wait = WebDriverWait(self.driver, 15)
            
            # ìƒˆë¡œìš´ ì½˜í…ì¸  ì¶”ì¶œê¸° ì´ˆê¸°í™”
            extraction_config = ExtractionConfig(
                timeout_seconds=int(os.getenv('CONTENT_EXTRACTION_TIMEOUT', '30')),
                min_content_length=int(os.getenv('CONTENT_MIN_LENGTH', '30')),
                max_content_length=int(os.getenv('CONTENT_MAX_LENGTH', '2000')),
                retry_count=int(os.getenv('EXTRACTION_RETRY_COUNT', '3')),
                enable_debug_screenshot=os.getenv('DEBUG_SCREENSHOT_ENABLED', 'true').lower() == 'true'
            )
            
            self.content_extractor = ContentExtractor(self.driver, self.wait, extraction_config)
            
            logging.info("âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ë° ì½˜í…ì¸  ì¶”ì¶œê¸° ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logging.error(f"âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def login_naver(self):
        """ë„¤ì´ë²„ ë¡œê·¸ì¸"""
        try:
            # ìë™í™” íƒì§€ ìš°íšŒ
            self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                '''
            })
            
            self.driver.get('https://nid.naver.com/nidlogin.login')
            time.sleep(3)
            
            # ID/PW ì…ë ¥
            id_input = self.driver.find_element(By.ID, 'id')
            pw_input = self.driver.find_element(By.ID, 'pw')
            
            self.driver.execute_script("""
                arguments[0].value = arguments[1];
                arguments[0].dispatchEvent(new Event('input', { bubbles: true }));
            """, id_input, os.getenv('NAVER_ID'))
            
            time.sleep(1)
            
            self.driver.execute_script("""
                arguments[0].value = arguments[1];
                arguments[0].dispatchEvent(new Event('input', { bubbles: true }));
            """, pw_input, os.getenv('NAVER_PW'))
            
            time.sleep(1)
            
            # ë¡œê·¸ì¸ í´ë¦­
            login_btn = self.driver.find_element(By.ID, 'log.login')
            self.driver.execute_script("arguments[0].click();", login_btn)
            
            time.sleep(10)
            
            if any(x in self.driver.current_url for x in ['naver.com', 'main']):
                logging.info("âœ… ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ")
                return True
            else:
                logging.warning("âš ï¸ ë¡œê·¸ì¸ í™•ì¸ í•„ìš”")
                return True
                
        except Exception as e:
            logging.error(f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def get_article_content(self, url: str) -> str:
        """
        ê²Œì‹œë¬¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° - í˜ì‹ ì ì¸ JavaScript ì‹¤í–‰ ë°©ì‹
        """
        try:
            logging.info(f"ğŸš€ JavaScript ê¸°ë°˜ ë‚´ìš© ì¶”ì¶œ ì‹œì‘: {url}")
            
            # ê²Œì‹œë¬¼ í˜ì´ì§€ë¡œ ì´ë™
            self.driver.get(url)
            time.sleep(8)  # ì¶©ë¶„í•œ ë¡œë”© ì‹œê°„
            
            # ë¡œê·¸ì¸ ì²´í¬
            if 'nid.naver.com' in self.driver.current_url:
                if self.login_naver():
                    self.driver.get(url)
                    time.sleep(8)
                else:
                    return "ë¡œê·¸ì¸ í•„ìš”"
            
            # iframe ì „í™˜
            try:
                self.wait.until(EC.frame_to_be_available_and_switch_to_it('cafe_main'))
                time.sleep(5)
                logging.info("âœ… iframe ì „í™˜ ì„±ê³µ")
            except:
                logging.warning("âš ï¸ iframe ì „í™˜ ì‹¤íŒ¨")
            
            # í˜ì´ì§€ ì™„ì „ ë¡œë”© ëŒ€ê¸°
            time.sleep(3)
            
            # ë””ë²„ê¹…: í˜„ì¬ í˜ì´ì§€ ì •ë³´ ì¶œë ¥
            logging.info(f"ğŸ” í˜„ì¬ URL: {self.driver.current_url}")
            logging.info(f"ğŸ” í˜ì´ì§€ ì œëª©: {self.driver.title}")
            
            # JavaScriptë¡œ ì§ì ‘ ë‚´ìš© ì¶”ì¶œ
            content = self._extract_with_javascript()
            
            # iframeì—ì„œ ë‚˜ì˜¤ê¸°
            try:
                self.driver.switch_to.default_content()
            except:
                pass
            
            if content and len(content.strip()) > 10:
                # JavaScript ì˜¤ë¥˜ ë©”ì‹œì§€ ì²´í¬
                if "We're sorry but web-pc doesn't work properly" in content:
                    logging.warning("âš ï¸ JavaScript ì˜¤ë¥˜ ë©”ì‹œì§€ ê°ì§€, ëŒ€ì²´ ë°©ë²• ì‹œë„")
                    content = self._extract_with_alternative_method()
                
                logging.info(f"âœ… ë‚´ìš© ì¶”ì¶œ ì„±ê³µ: {len(content)}ì")
                return content[:1500]
            else:
                return "ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨"
                
        except Exception as e:
            logging.error(f"âŒ JavaScript ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            try:
                self.driver.switch_to.default_content()
            except:
                pass
            return f"ì¶”ì¶œ ì˜¤ë¥˜: {str(e)[:50]}"
    
    def _extract_with_javascript(self) -> str:
        """JavaScriptë¥¼ ì‚¬ìš©í•œ ì§ì ‘ DOM ì¡°ì‘"""
        try:
            # 1. SmartEditor í…ìŠ¤íŠ¸ ì¶”ì¶œ JavaScript
            js_script = """
            var content = [];
            
            // ë°©ë²• 1: se-text-paragraph ë‚´ì˜ ëª¨ë“  í…ìŠ¤íŠ¸
            var paragraphs = document.querySelectorAll('p.se-text-paragraph');
            paragraphs.forEach(function(p) {
                var spans = p.querySelectorAll('span');
                spans.forEach(function(span) {
                    var text = span.innerText || span.textContent;
                    if (text && text.trim().length > 2) {
                        content.push(text.trim());
                    }
                });
                
                // spanì´ ì—†ìœ¼ë©´ p ì§ì ‘ í…ìŠ¤íŠ¸
                if (spans.length === 0) {
                    var text = p.innerText || p.textContent;
                    if (text && text.trim().length > 2) {
                        content.push(text.trim());
                    }
                }
            });
            
            // ë°©ë²• 2: se-component ë‚´ì˜ ëª¨ë“  í…ìŠ¤íŠ¸
            if (content.length === 0) {
                var components = document.querySelectorAll('.se-component');
                components.forEach(function(comp) {
                    var text = comp.innerText || comp.textContent;
                    if (text && text.trim().length > 5) {
                        content.push(text.trim());
                    }
                });
            }
            
            // ë°©ë²• 3: se-main-container ì „ì²´
            if (content.length === 0) {
                var mainContainer = document.querySelector('.se-main-container');
                if (mainContainer) {
                    var text = mainContainer.innerText || mainContainer.textContent;
                    if (text && text.trim().length > 10) {
                        content.push(text.trim());
                    }
                }
            }
            
            // ë°©ë²• 4: ëª¨ë“  í…ìŠ¤íŠ¸ ë…¸ë“œ ìˆ˜ì§‘ (ìµœí›„ì˜ ìˆ˜ë‹¨)
            if (content.length === 0) {
                var walker = document.createTreeWalker(
                    document.body,
                    NodeFilter.SHOW_TEXT,
                    {
                        acceptNode: function(node) {
                            var text = node.textContent.trim();
                            if (text.length > 5 && 
                                !text.includes('javascript') && 
                                !text.includes('login') &&
                                !text.includes('NAVER')) {
                                return NodeFilter.FILTER_ACCEPT;
                            }
                            return NodeFilter.FILTER_REJECT;
                        }
                    }
                );
                
                var textNodes = [];
                var node;
                while (node = walker.nextNode()) {
                    textNodes.push(node.textContent.trim());
                }
                
                if (textNodes.length > 0) {
                    content = textNodes.slice(0, 20); // ì²˜ìŒ 20ê°œë§Œ
                }
            }
            
            return content.join('\\n');
            """
            
            result = self.driver.execute_script(js_script)
            
            if result and len(result.strip()) > 10:
                logging.info(f"âœ… JavaScript ìŠ¤í¬ë¦½íŠ¸ ì„±ê³µ: {len(result)}ì")
                return result
            
            # í´ë°±: ë” ê°„ë‹¨í•œ JavaScript
            simple_js = """
            var allText = document.body.innerText || document.body.textContent;
            var lines = allText.split('\\n');
            var goodLines = [];
            
            for (var i = 0; i < lines.length && goodLines.length < 15; i++) {
                var line = lines[i].trim();
                if (line.length > 5 && 
                    !line.includes('javascript') && 
                    !line.includes('login') &&
                    !line.includes('NAVER Corp')) {
                    goodLines.push(line);
                }
            }
            
            return goodLines.join('\\n');
            """
            
            fallback_result = self.driver.execute_script(simple_js)
            if fallback_result:
                logging.info(f"âœ… JavaScript í´ë°± ì„±ê³µ: {len(fallback_result)}ì")
                return fallback_result
            
            return ""
            
        except Exception as e:
            logging.error(f"âŒ JavaScript ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return ""
    
    def _extract_author_with_javascript(self, url: str) -> str:
        """JavaScriptë¡œ ì‘ì„±ì ì¶”ì¶œ"""
        try:
            # í˜„ì¬ URLì´ ê²Œì‹œë¬¼ í˜ì´ì§€ì¸ì§€ í™•ì¸
            current_url = self.driver.current_url
            if url not in current_url:
                return "Unknown"
            
            # JavaScriptë¡œ ì‘ì„±ì ì¶”ì¶œ
            author_js = """
            var author = '';
            
            // ë°©ë²• 1: button.nickname
            var nicknameBtn = document.querySelector('button.nickname');
            if (nicknameBtn) {
                author = nicknameBtn.innerText || nicknameBtn.textContent;
            }
            
            // ë°©ë²• 2: button[id*="writerInfo"]
            if (!author) {
                var writerBtn = document.querySelector('button[id*="writerInfo"]');
                if (writerBtn) {
                    author = writerBtn.innerText || writerBtn.textContent;
                }
            }
            
            // ë°©ë²• 3: .nickname í´ë˜ìŠ¤
            if (!author) {
                var nicknameElem = document.querySelector('.nickname');
                if (nicknameElem) {
                    author = nicknameElem.innerText || nicknameElem.textContent;
                }
            }
            
            // ë°©ë²• 4: ëª¨ë“  button íƒœê·¸ì—ì„œ ì°¾ê¸°
            if (!author) {
                var buttons = document.querySelectorAll('button');
                for (var i = 0; i < buttons.length; i++) {
                    var btn = buttons[i];
                    var text = btn.innerText || btn.textContent;
                    if (text && text.trim().length > 0 && text.trim().length < 20) {
                        // ì‘ì„±ì ê°™ì€ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                        if (!text.includes('ë¡œê·¸ì¸') && !text.includes('ë©”ë‰´') && 
                            !text.includes('ê²€ìƒ‰') && !text.includes('ë“±ë¡')) {
                            author = text.trim();
                            break;
                        }
                    }
                }
            }
            
            return author ? author.trim() : '';
            """
            
            result = self.driver.execute_script(author_js)
            
            if result and len(result.strip()) > 0:
                logging.info(f"âœ… JavaScript ì‘ì„±ì ì¶”ì¶œ ì„±ê³µ: {result}")
                return result.strip()
            
            return "Unknown"
            
        except Exception as e:
            logging.error(f"âŒ JavaScript ì‘ì„±ì ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "Unknown"
    
    def _extract_with_alternative_method(self) -> str:
        """ëŒ€ì²´ ì¶”ì¶œ ë°©ë²• - ë” ì§ì ‘ì ì¸ ì ‘ê·¼"""
        try:
            # ë” ê°„ë‹¨í•œ JavaScriptë¡œ ì‹¤ì œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            simple_js = """
            // ëª¨ë“  í…ìŠ¤íŠ¸ ë…¸ë“œë¥¼ ì°¾ì•„ì„œ ì‹¤ì œ ë‚´ìš©ë§Œ ì¶”ì¶œ
            var walker = document.createTreeWalker(
                document.body,
                NodeFilter.SHOW_TEXT,
                null,
                false
            );
            
            var textContent = [];
            var node;
            
            while (node = walker.nextNode()) {
                var text = node.textContent.trim();
                var parent = node.parentElement;
                
                // ë¶€ëª¨ ìš”ì†Œê°€ se-text-paragraphì¸ ê²½ìš° ìš°ì„  ìˆ˜ì§‘
                if (parent && parent.className && parent.className.includes('se-text-paragraph')) {
                    if (text.length > 3 && !text.includes('javascript') && !text.includes('We\\'re sorry')) {
                        textContent.push(text);
                    }
                }
            }
            
            // se-text-paragraphì—ì„œ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            if (textContent.length === 0) {
                walker = document.createTreeWalker(
                    document.body,
                    NodeFilter.SHOW_TEXT,
                    null,
                    false
                );
                
                while (node = walker.nextNode()) {
                    var text = node.textContent.trim();
                    if (text.length > 10 && 
                        !text.includes('javascript') && 
                        !text.includes('We\\'re sorry') &&
                        !text.includes('NAVER') &&
                        !text.includes('ë¡œê·¸ì¸')) {
                        textContent.push(text);
                    }
                }
            }
            
            return textContent.slice(0, 10).join('\\n');
            """
            
            result = self.driver.execute_script(simple_js)
            
            if result and len(result.strip()) > 20:
                logging.info(f"âœ… ëŒ€ì²´ ë°©ë²• ì„±ê³µ: {len(result)}ì")
                return result
            
            return "ëŒ€ì²´ ë°©ë²•ë„ ì‹¤íŒ¨"
            
        except Exception as e:
            logging.error(f"âŒ ëŒ€ì²´ ë°©ë²• ì‹¤íŒ¨: {e}")
            return "ëŒ€ì²´ ë°©ë²• ì˜¤ë¥˜"
    
    def _is_system_text(self, text: str) -> bool:
        """ì‹œìŠ¤í…œ í…ìŠ¤íŠ¸ì¸ì§€ íŒë‹¨"""
        system_keywords = [
            'javascript', 'cookie', 'privacy', 'terms', 'login', 'menu',
            'navigation', 'footer', 'header', 'advertisement', 'loading',
            'ID/Phone number', 'Stay Signed in', 'IP Security', 'Passkey',
            'NAVER Corp', 'ë„¤ì´ë²„', 'ë¡œê·¸ì¸', 'ë©”ë‰´', 'ê´‘ê³ '
        ]
        
        text_lower = text.lower()
        return any(keyword.lower() in text_lower for keyword in system_keywords)
    
    def _contains_login_text(self, text: str) -> bool:
        """ë¡œê·¸ì¸ ê´€ë ¨ í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€"""
        login_keywords = [
            'ID/Phone number', 'Stay Signed in', 'IP Security', 'Passkey login',
            'NAVER Corp', 'All Rights Reserved', 'sign in', 'login'
        ]
        
        return any(keyword in text for keyword in login_keywords)
    

    
    def _extract_real_content(self) -> str:
        """ì‹¤ì œ ê²Œì‹œë¬¼ ë‚´ìš©ë§Œ ì¶”ì¶œ"""
        try:
            content_parts = []
            
            # F-E ì¹´í˜ SmartEditor ì„ íƒìë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
            selectors = [
                # SmartEditor 3.0
                '.se-main-container .se-component .se-text-paragraph',
                '.se-main-container .se-text',
                '.se-main-container p',
                '.se-main-container div',
                
                # SmartEditor 2.0
                '.se-component-content',
                '.se-text-paragraph',
                
                # ì¼ë°˜ ê²Œì‹œë¬¼
                '.article_viewer .se-main-container',
                '.post-view .article-board-content',
                '.ArticleContentBox',
                '#content-area .se-main-container',
                
                # ë ˆê±°ì‹œ
                '.article_viewer',
                '.board-content',
                '.content_text',
                '#content-area'
            ]
            
            for selector in selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        for element in elements:
                            text = element.text.strip()
                            if text and len(text) > 10:
                                # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ í•„í„°ë§
                                if not self._is_unwanted_text(text):
                                    content_parts.append(text)
                        
                        if content_parts:
                            content = '\n'.join(content_parts)
                            if len(content) > 50:
                                logging.info(f"âœ… ì„ íƒì '{selector}' ì„±ê³µ: {len(content)}ì")
                                return content
                except Exception as e:
                    logging.debug(f"ì„ íƒì {selector} ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  ì„ íƒì ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ìš”ì†Œ ì „ì²´ ìŠ¤ìº”
            logging.info("ğŸ” ì „ì²´ í…ìŠ¤íŠ¸ ìš”ì†Œ ìŠ¤ìº” ì‹œì‘")
            all_text_elements = self.driver.find_elements(By.CSS_SELECTOR, 'p, div, span')
            
            for element in all_text_elements:
                try:
                    text = element.text.strip()
                    if text and len(text) > 20 and not self._is_unwanted_text(text):
                        content_parts.append(text)
                except:
                    continue
            
            if content_parts:
                # ì¤‘ë³µ ì œê±°
                unique_parts = list(dict.fromkeys(content_parts))
                content = '\n'.join(unique_parts[:15])  # ì²˜ìŒ 15ê°œë§Œ
                if len(content) > 100:
                    logging.info(f"âœ… ì „ì²´ ìŠ¤ìº” ì„±ê³µ: {len(content)}ì")
                    return content
            
            return ""
            
        except Exception as e:
            logging.error(f"âŒ ì‹¤ì œ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _is_unwanted_text(self, text: str) -> bool:
        """ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ì¸ì§€ íŒë‹¨"""
        unwanted_keywords = [
            'ID/Phone number', 'Stay Signed in', 'IP Security', 'Passkey login',
            'NAVER Corp', 'All Rights Reserved', 'javascript', 'cookie',
            'privacy', 'terms', 'login', 'sign in', 'forgot', 'customer service',
            'menu', 'navigation', 'footer', 'header', 'sidebar', 'advertisement',
            'loading', 'please wait', 'error', 'ì˜¤ë¥˜', 'ë¡œë”©', 'ë©”ë‰´', 'ë„¤ë¹„ê²Œì´ì…˜'
        ]
        
        text_lower = text.lower()
        return any(keyword.lower() in text_lower for keyword in unwanted_keywords)

    def _direct_content_extraction(self, url: str) -> str:
        """ì§ì ‘ì ì¸ ë‚´ìš© ì¶”ì¶œ ë°©ë²•"""
        try:
            logging.info(f"ğŸ¯ ì§ì ‘ ì¶”ì¶œ ì‹œì‘: {url}")
            
            # í˜ì´ì§€ ì´ë™
            self.driver.get(url)
            time.sleep(8)  # ì¶©ë¶„í•œ ë¡œë”© ì‹œê°„
            
            # F-E ì¹´í˜ íŠ¹í™” ì¶”ì¶œ
            content = ""
            
            # 1. iframe ì „í™˜ ì‹œë„
            try:
                self.wait.until(EC.frame_to_be_available_and_switch_to_it('cafe_main'))
                logging.info("âœ… iframe ì „í™˜ ì„±ê³µ")
                time.sleep(5)
            except:
                logging.warning("âš ï¸ iframe ì „í™˜ ì‹¤íŒ¨, ë©”ì¸ í˜ì´ì§€ì—ì„œ ì‹œë„")
            
            # 2. F-E ì¹´í˜ ì „ìš© ì„ íƒìë“¤
            fe_selectors = [
                '.se-main-container .se-component',
                '.se-main-container',
                '.article_viewer .se-main-container',
                '.post-view .se-main-container',
                '.ArticleContentBox .se-main-container',
                '.se-component-content',
                '.se-text-paragraph',
                '.article-board-content',
                '.post-content',
                '#content-area .se-main-container'
            ]
            
            for selector in fe_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        for element in elements:
                            text = element.text.strip()
                            if text and len(text) > 30:
                                content += text + "\n"
                        
                        if content and len(content.strip()) > 50:
                            logging.info(f"âœ… ì§ì ‘ ì¶”ì¶œ ì„±ê³µ (ì„ íƒì: {selector}): {len(content)}ì")
                            self.driver.switch_to.default_content()
                            return content.strip()
                except Exception as e:
                    logging.debug(f"ì„ íƒì {selector} ì‹¤íŒ¨: {e}")
                    continue
            
            # 3. ì¼ë°˜ì ì¸ ì„ íƒìë“¤
            general_selectors = [
                '.article_viewer',
                '.board-content',
                '.content_text',
                '#content-area',
                '.post-content',
                '.article-content'
            ]
            
            for selector in general_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        text = elements[0].text.strip()
                        if text and len(text) > 50:
                            logging.info(f"âœ… ì¼ë°˜ ì„ íƒì ì„±ê³µ ({selector}): {len(text)}ì")
                            self.driver.switch_to.default_content()
                            return text
                except:
                    continue
            
            self.driver.switch_to.default_content()
            return ""
            
        except Exception as e:
            logging.error(f"âŒ ì§ì ‘ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            try:
                self.driver.switch_to.default_content()
            except:
                pass
            return ""
    
    def _fallback_content_extraction(self, url: str) -> str:
        """í´ë°± ë‚´ìš© ì¶”ì¶œ ë°©ë²• - ìµœí›„ì˜ ìˆ˜ë‹¨"""
        try:
            logging.info(f"ğŸ†˜ ìµœí›„ ìˆ˜ë‹¨ ì¶”ì¶œ ì‹œë„: {url}")
            
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            self.driver.refresh()
            time.sleep(10)
            
            # ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œì—ì„œ ì¶”ì¶œ ì‹œë„
            try:
                # ëª¨ë“  p, div, span íƒœê·¸ì—ì„œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                text_elements = self.driver.find_elements(By.CSS_SELECTOR, 'p, div, span')
                content_parts = []
                
                for element in text_elements:
                    try:
                        text = element.text.strip()
                        if text and len(text) > 10:
                            # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ í•„í„°ë§
                            if not any(skip in text.lower() for skip in [
                                'javascript', 'cookie', 'privacy', 'terms', 'login', 'menu',
                                'navigation', 'footer', 'header', 'sidebar', 'advertisement'
                            ]):
                                content_parts.append(text)
                    except:
                        continue
                
                if content_parts:
                    # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
                    unique_parts = []
                    for part in content_parts:
                        if part not in unique_parts and len(part) > 15:
                            unique_parts.append(part)
                    
                    final_content = '\n'.join(unique_parts[:10])  # ì²˜ìŒ 10ê°œ ë¬¸ë‹¨ë§Œ
                    if len(final_content) > 100:
                        logging.info(f"âœ… ìµœí›„ ìˆ˜ë‹¨ ì„±ê³µ: {len(final_content)}ì")
                        return final_content
            except:
                pass
            
            # ì •ë§ ìµœí›„ì˜ ìˆ˜ë‹¨: ì œëª©ë§Œì´ë¼ë„ ì €ì¥
            try:
                title_element = self.driver.find_element(By.CSS_SELECTOR, 'h1, h2, h3, .title, .subject')
                title = title_element.text.strip()
                if title:
                    return f"[ì œëª©ë§Œ ì¶”ì¶œë¨]\n\n{title}\n\nì „ì²´ ë‚´ìš©ì„ ë³´ë ¤ë©´ ë§í¬ë¥¼ í™•ì¸í•˜ì„¸ìš”: {url}"
            except:
                pass
            
            return f"[ë‚´ìš© ì¶”ì¶œ ì™„ì „ ì‹¤íŒ¨]\n\nê²Œì‹œë¬¼ ë§í¬: {url}\n\nìˆ˜ë™ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
            
        except Exception as e:
            logging.error(f"âŒ ìµœí›„ ìˆ˜ë‹¨ë„ ì‹¤íŒ¨: {e}")
            return f"[ì‹œìŠ¤í…œ ì˜¤ë¥˜]\n\nê²Œì‹œë¬¼ ë§í¬: {url}\n\nì˜¤ë¥˜: {str(e)[:100]}"
    
    def crawl_cafe(self, cafe_config: Dict) -> List[Dict]:
        """ì¹´í˜ ê²Œì‹œë¬¼ í¬ë¡¤ë§"""
        results = []
        
        try:
            # ì¹´í˜ ê²Œì‹œíŒ ì ‘ì† - F-E ì¹´í˜ URL êµ¬ì¡°ì— ë§ì¶¤
            if cafe_config['name'] == 'F-E ì¹´í˜':
                # F-E ì¹´í˜ ì „ìš© URL êµ¬ì¡°
                board_url = f"{cafe_config['url']}/cafes/{cafe_config['club_id']}/menus/{cafe_config['board_id']}?viewType=L"
            else:
                # ì¼ë°˜ ì¹´í˜ URL êµ¬ì¡°
                board_url = f"{cafe_config['url']}/ArticleList.nhn?search.clubid={cafe_config['club_id']}&search.menuid={cafe_config['board_id']}"
            logging.info(f"ğŸ“ URL ì ‘ì†: {board_url}")
            self.driver.get(board_url)
            time.sleep(5)
            
            # iframe ì „í™˜
            try:
                self.driver.switch_to.frame('cafe_main')
                time.sleep(2)
            except:
                logging.warning("iframe ì „í™˜ ì‹¤íŒ¨")
            
            # ê²Œì‹œë¬¼ ì°¾ê¸°
            articles = []
            selectors = [
                'div.article-board table tbody tr',
                'ul.article-movie-sub li',
                'div.ArticleListItem'
            ]
            
            for selector in selectors:
                try:
                    articles = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if articles:
                        logging.info(f"âœ… ê²Œì‹œë¬¼ ë°œê²¬: {len(articles)}ê°œ")
                        break
                except:
                    continue
            
            if not articles:
                logging.warning("ê²Œì‹œë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return results
            
            # ê³µì§€ ì œì™¸ (ì—¬ëŸ¬ íŒ¨í„´ ì²˜ë¦¬)
            actual_articles = []
            for article in articles:
                try:
                    is_notice = False
                    # í´ë˜ìŠ¤ ê¸°ë°˜
                    try:
                        cls = (article.get_attribute('class') or '').lower()
                        if 'notice' in cls:
                            is_notice = True
                    except:
                        pass

                    # ì‹œê°ì  ì•„ì´ì½˜/í‘œì‹œ ê¸°ë°˜
                    if not is_notice:
                        try:
                            if article.find_elements(By.CSS_SELECTOR, 'img[alt="ê³µì§€"], .notice, .icon_notice, .board-notice, .ArticleList__notice'):
                                is_notice = True
                        except:
                            pass

                    # ì…€ í…ìŠ¤íŠ¸ ê¸°ë°˜
                    if not is_notice:
                        try:
                            td_article_elems = article.find_elements(By.CSS_SELECTOR, 'td, th, .td_article')
                            for td in td_article_elems[:2]:
                                t = td.text.strip()
                                if t == 'ê³µì§€' or t.startswith('ê³µì§€') or '[ê³µì§€]' in t:
                                    is_notice = True
                                    break
                        except:
                            pass

                    # ì „ì²´ í…ìŠ¤íŠ¸ ê²€ì‚¬ (ìµœí›„ì˜ ìˆ˜ë‹¨)
                    if not is_notice:
                        text = (article.text or '').strip()
                        if not text or 'ê³µì§€' in text:
                            # ê³µë°±ì´ê±°ë‚˜ ê³µì§€ í¬í•¨ì´ë©´ ì œì™¸
                            if 'ê³µì§€' in text:
                                is_notice = True
                            else:
                                # ê³µë°±ì€ ì œì™¸í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰
                                pass

                    if is_notice:
                        continue
                    actual_articles.append(article)
                except:
                    # ì˜¤ë¥˜ ì‹œì—ëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ í¬í•¨
                    actual_articles.append(article)
            
            logging.info(f"ğŸ“Š ê³µì§€ ì œì™¸ ì‹¤ì œ ê²Œì‹œë¬¼: {len(actual_articles)}ê°œ")
            
            # ìµœëŒ€ 10ê°œ ì²˜ë¦¬ (ì‹¤ì œ ìš´ì˜ìš©)
            max_articles = 10
            processed = 0
            
            # ê²Œì‹œë¬¼ ì²˜ë¦¬ - ë” ê²¬ê³ í•œ ë°©ì‹
            for i, article in enumerate(actual_articles[:20]):
                if processed >= max_articles:
                    logging.info(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±: {processed}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
                    break
                
                try:
                    logging.info(f"ğŸ”„ [{i+1}/{len(actual_articles[:20])}] ê²Œì‹œë¬¼ ì²˜ë¦¬ ì¤‘...")
                    
                    # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
                    title = ""
                    link = ""
                    
                    # F-E ì¹´í˜ ì „ìš© ë§í¬ ì¶”ì¶œ - JavaScript ì‚¬ìš©
                    try:
                        js_extract_link = f"""
                        var articles = document.querySelectorAll('div, tr, li');
                        var result = null;
                        
                        for (var i = {i}; i < articles.length && i < {i+1}; i++) {{
                            var article = articles[i];
                            var links = article.querySelectorAll('a[href*="articles"], a[href*="articleid"]');
                            
                            for (var j = 0; j < links.length; j++) {{
                                var link = links[j];
                                var href = link.href;
                                var text = link.innerText || link.textContent;
                                
                                if (href && text && text.trim().length > 3 && 
                                    (href.includes('articles/') || href.includes('articleid='))) {{
                                    result = {{
                                        title: text.trim(),
                                        url: href
                                    }};
                                    break;
                                }}
                            }}
                            
                            if (result) break;
                        }}
                        
                        return result;
                        """
                        
                        js_result = self.driver.execute_script(js_extract_link)
                        
                        if js_result and js_result.get('title') and js_result.get('url'):
                            title = js_result['title']
                            link = js_result['url']
                            logging.info(f"âœ… JavaScript ë§í¬ ì¶”ì¶œ ì„±ê³µ: {title[:30]}")
                        else:
                            # í´ë°±: ê¸°ì¡´ ë°©ì‹
                            selectors = [
                                'a[href*="articles"]',
                                'a[href*="articleid"]', 
                                'td.td_article a',
                                'a.article',
                                'a'
                            ]
                            
                            for selector in selectors:
                                try:
                                    link_elem = article.find_element(By.CSS_SELECTOR, selector)
                                    title = link_elem.text.strip()
                                    link = link_elem.get_attribute('href')
                                    
                                    if title and link and ('articles/' in link or 'articleid=' in link):
                                        break
                                except:
                                    continue
                    except Exception as e:
                        logging.error(f"âŒ JavaScript ë§í¬ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                        continue
                    
                    # ê¸°ë³¸ ê²€ì¦
                    if not title or not link:
                        logging.warning(f"âš ï¸ [{i+1}] ì œëª© ë˜ëŠ” ë§í¬ ì—†ìŒ, ê±´ë„ˆëœ€")
                        continue
                    
                    if 'ê³µì§€' in title or len(title) < 3:
                        logging.warning(f"âš ï¸ [{i+1}] ê³µì§€ ë˜ëŠ” ì œëª© ë¶€ì ì ˆ: {title[:20]}")
                        continue
                    
                    # URL ì •ë¦¬
                    if link.endswith('#'):
                        link = link[:-1]
                    if link.startswith('/'):
                        link = 'https://cafe.naver.com' + link
                    
                    logging.info(f"ğŸ“ [{i+1}] ì²˜ë¦¬ ì‹œì‘: {title[:30]}...")
                    logging.info(f"ğŸ”— [{i+1}] URL: {link}")
                    
                    # ë‚´ìš© ì¶”ì¶œ
                    try:
                        content = self.get_article_content(link)
                        logging.info(f"ğŸ“„ [{i+1}] ë‚´ìš© ê¸¸ì´: {len(content)}ì")
                    except Exception as content_error:
                        logging.error(f"âŒ [{i+1}] ë‚´ìš© ì¶”ì¶œ ì˜¤ë¥˜: {content_error}")
                        content = f"ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(content_error)[:100]}"
                    
                    # ì‘ì„±ì ì¶”ì¶œ - JavaScript ë°©ì‹
                    author = self._extract_author_with_javascript(link)
                    if not author or author == "Unknown":
                        # í´ë°±: ê²Œì‹œë¬¼ ëª©ë¡ì—ì„œ ì¶”ì¶œ
                        try:
                            author_elem = article.find_element(By.CSS_SELECTOR, 'td.td_name, .name, .author, .nickname')
                            author = author_elem.text.strip() or "Unknown"
                        except:
                            author = "Unknown"
                    
                    # ì‘ì„±ì¼ ì¶”ì¶œ
                    date_str = datetime.now().strftime('%Y-%m-%d')
                    try:
                        date_elem = article.find_element(By.CSS_SELECTOR, 'td.td_date, .date, .time')
                        date_text = date_elem.text.strip()
                        if date_text:
                            date_str = date_text.replace('.', '-').rstrip('-')
                    except:
                        pass
                    
                    # ë°ì´í„° êµ¬ì„±
                    data = {
                        'title': title,
                        'author': author,
                        'date': date_str,
                        'url': link,
                        'article_id': link.split('/')[-1].split('?')[0],
                        'content': content,
                        'cafe_name': cafe_config['name'],
                        'crawled_at': datetime.now().isoformat()
                    }
                    
                    results.append(data)
                    processed += 1
                    logging.info(f"âœ… [{processed}/{max_articles}] ì™„ë£Œ: {title[:30]}...")
                    
                    # ë‹¤ìŒ ê²Œì‹œë¬¼ ì²˜ë¦¬ ì „ ì ì‹œ ëŒ€ê¸°
                    time.sleep(1)
                    
                except Exception as e:
                    logging.error(f"âŒ [{i+1}] ê²Œì‹œë¬¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ ê²Œì‹œë¬¼ ê³„ì† ì²˜ë¦¬
                    continue
            
            logging.info(f"ğŸ¯ ê²Œì‹œë¬¼ ì²˜ë¦¬ ì™„ë£Œ: {processed}ê°œ ì„±ê³µ")
            
            self.driver.switch_to.default_content()
            
        except Exception as e:
            logging.error(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        
        return results
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            logging.info("âœ… ë“œë¼ì´ë²„ ì¢…ë£Œ")


class NotionDatabase:
    """ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤"""
    
    def __init__(self):
        self.client = Client(auth=os.getenv('NOTION_TOKEN'))
        self.database_id = os.getenv('NOTION_DATABASE_ID')
    
    def check_duplicate(self, url: str) -> bool:
        """ì¤‘ë³µ ì²´í¬ - URL í•„ë“œ ê¸°ë°˜"""
        try:
            logging.debug(f"ğŸ” ì¤‘ë³µ ì²´í¬: {url}")
            
            # URLë¡œ ì¤‘ë³µ ì²´í¬
            query_filter = {
                "property": "URL",
                "url": {"equals": url}
            }

            response = self.client.databases.query(
                database_id=self.database_id,
                filter=query_filter
            )
            
            num_results = len(response.get('results', []))
            is_duplicate = num_results > 0
            
            if is_duplicate:
                logging.debug(f"  ğŸ”´ ì¤‘ë³µ ë°œê²¬: {num_results}ê°œ")
            else:
                logging.debug(f"  ğŸŸ¢ ìƒˆë¡œìš´ ê²Œì‹œë¬¼")
            
            return is_duplicate

        except Exception as e:
            logging.error(f"âŒ ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œì—ëŠ” ì¤‘ë³µì´ ì•„ë‹ˆë¼ê³  íŒë‹¨ (ì•ˆì „ì¥ì¹˜)
            return False
    
    def save_article(self, article: Dict) -> bool:
        """ê²Œì‹œë¬¼ ì €ì¥ - ë…¸ì…˜ DB êµ¬ì¡°ì— ë§ì¶¤"""
        try:
            # TODO: í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ì¤‘ë³µ ì²´í¬ ë‹¤ì‹œ í™œì„±í™”
            # if self.check_duplicate(article['url']):
            #     logging.info(f"â­ï¸ ì¤‘ë³µ: {article['title'][:30]}...")
            #     return False
            
            logging.info(f"ğŸ’¾ ì¤‘ë³µ ì²´í¬ ë¹„í™œì„±í™” - ê°•ì œ ì €ì¥ ì‹œë„: {article['title'][:30]}...")
            
            # ë…¸ì…˜ ì†ì„± (ì •í™•í•œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ì— ë§ì¶¤)
            properties = {}
            
            # 1. ì œëª© - Title í•„ë“œ
            title = article.get('title', '').strip() or "ì œëª© ì—†ìŒ"
            if len(title) > 100:
                title = title[:97] + "..."
            
            properties["ì œëª©"] = {
                "title": [{"text": {"content": title}}]
            }
            
            # 2. ì‘ì„±ì - Text í•„ë“œ
            author = article.get('author', 'Unknown').strip()
            properties["ì‘ì„±ì"] = {
                "rich_text": [{"text": {"content": author}}]
            }
            
            # 3. ì‘ì„±ì¼ - Text í•„ë“œ
            date_str = article.get('date', datetime.now().strftime('%Y-%m-%d'))
            properties["ì‘ì„±ì¼"] = {
                "rich_text": [{"text": {"content": date_str}}]
            }
            
            # 4. URL - URL í•„ë“œ
            if article.get('url'):
                properties["URL"] = {"url": article['url']}
            
            # 5. ë‚´ìš© - Text í•„ë“œ
            content = article.get('content', '').strip()
            if not content:
                content = "[ë‚´ìš© ì—†ìŒ]"
            
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (ë…¸ì…˜ Rich Text ì œí•œ ê³ ë ¤)
            if len(content) > 2000:
                content = content[:1997] + "..."
            
            properties["ë‚´ìš©"] = {
                "rich_text": [{"text": {"content": content}}]
            }
            
            # 6. í¬ë¡¤ë§ ì¼ì‹œ - ë‚ ì§œ í•„ë“œ (í˜„ì¬ ì‹œê°„)
            properties["í¬ë¡¤ë§ ì¼ì‹œ"] = {
                "date": {"start": datetime.now().isoformat()}
            }
            
            # 7. ì¹´í˜ëª… - Select í•„ë“œ
            cafe_name = article.get('cafe_name', 'Unknown')
            properties["ì¹´í˜ëª…"] = {
                "select": {"name": cafe_name}
            }
            
            # 8. uploaded - Checkbox í•„ë“œ (ê¸°ë³¸ê°’: false)
            properties["uploaded"] = {"checkbox": False}
            
            # í˜ì´ì§€ ìƒì„±
            page = self.client.pages.create(
                parent={"database_id": self.database_id},
                properties=properties
            )
            
            logging.info(f"âœ… ë…¸ì…˜ ì €ì¥ ì„±ê³µ: {title[:30]}...")
            return True
            
        except Exception as e:
            logging.error(f"âŒ ë…¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")
            logging.error(f"   ê²Œì‹œë¬¼ ì •ë³´: {article.get('title', 'Unknown')[:50]}")
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´
            import traceback
            logging.debug(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return False


def main():
    """ë©”ì¸"""
    logging.info("="*60)
    logging.info("ğŸš€ ë„¤ì´ë²„ ì¹´í˜ â†’ ë…¸ì…˜ í¬ë¡¤ë§ ì‹œì‘")
    logging.info(f"â° {datetime.now()}")
    logging.info("="*60)
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    required = ['NAVER_ID', 'NAVER_PW', 'NOTION_TOKEN', 'NOTION_DATABASE_ID']
    missing = [e for e in required if not os.getenv(e)]
    
    if missing:
        logging.error(f"âŒ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing)}")
        sys.exit(1)
    
    # ì¹´í˜ ì„¤ì • - F-E ì¹´í˜ë§Œ í¬ë¡¤ë§
    cafes = []
    
    # F-E ì¹´í˜ ì„¤ì • (ì œê³µëœ ì •ë³´ ê¸°ë°˜)
    cafes.append({
        'name': 'F-E ì¹´í˜',
        'url': 'https://cafe.naver.com/f-e',
        'club_id': '18786605',
        'board_id': '105'
    })
    
    # ì¶”ê°€ ì¹´í˜ëŠ” í™˜ê²½ë³€ìˆ˜ê°€ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ ì¶”ê°€
    # í˜„ì¬ëŠ” F-E ì¹´í˜ë§Œ í¬ë¡¤ë§í•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
    # if os.getenv('CAFE1_URL') and os.getenv('CAFE1_CLUB_ID') and os.getenv('CAFE1_BOARD_ID'):
    #     cafes.append({
    #         'name': os.getenv('CAFE1_NAME', 'ì¹´í˜1'),
    #         'url': os.getenv('CAFE1_URL'),
    #         'club_id': os.getenv('CAFE1_CLUB_ID'),
    #         'board_id': os.getenv('CAFE1_BOARD_ID')
    #     })
    
    logging.info(f"ğŸ“‹ ì„¤ì •ëœ ì¹´í˜ ìˆ˜: {len(cafes)}ê°œ")
    for i, cafe in enumerate(cafes, 1):
        logging.info(f"  {i}. {cafe['name']} (ID: {cafe['club_id']}, Board: {cafe['board_id']})")
    
    if not cafes:
        logging.error("âŒ ì¹´í˜ ì„¤ì • ì—†ìŒ")
        sys.exit(1)
    
    # í¬ë¡¤ëŸ¬ ì‹¤í–‰
    crawler = NaverCafeCrawler()
    notion = NotionDatabase()
    
    try:
        if not crawler.login_naver():
            raise Exception("ë¡œê·¸ì¸ ì‹¤íŒ¨")
        
        total = 0
        
        for cafe in cafes:
            logging.info(f"\nğŸ“ {cafe['name']} í¬ë¡¤ë§...")
            articles = crawler.crawl_cafe(cafe)
            
            saved = 0
            for article in articles:
                if notion.save_article(article):
                    saved += 1
                    total += 1
            
            logging.info(f"âœ… {cafe['name']}: {saved}ê°œ ì €ì¥")
            time.sleep(2)
        
        logging.info(f"\nğŸ‰ ì™„ë£Œ! ì´ {total}ê°œ ì €ì¥")
        
    except Exception as e:
        logging.error(f"âŒ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    finally:
        crawler.close()


if __name__ == "__main__":
    main()
