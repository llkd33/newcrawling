#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ë§ -> ë…¸ì…˜ ì €ì¥ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
ë§¤ì¼ ì •ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ ìƒˆ ê²Œì‹œë¬¼ì„ í¬ë¡¤ë§í•˜ê³  ë…¸ì…˜ì— ì €ì¥
"""

import os
import sys
import json
import time
import logging
from datetime import datetime, timedelta
from typing import List, Dict
from dotenv import load_dotenv
import hashlib

# Selenium imports
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service

# Notion imports
from notion_client import Client

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('crawler.log', encoding='utf-8')
    ]
)

class NaverCafeCrawler:
    """ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.driver = None
        self.wait = None
        self.setup_driver()
        
    def setup_driver(self):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì •"""
        options = Options()
        
        # GitHub Actions í™˜ê²½ì—ì„œëŠ” í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í•„ìˆ˜
        if os.getenv('GITHUB_ACTIONS'):
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
        
        # ê¸°ë³¸ ì˜µì…˜
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        try:
            self.driver = webdriver.Chrome(options=options)
            self.wait = WebDriverWait(self.driver, 10)
            logging.info("âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logging.error(f"âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def login_naver(self):
        """ë„¤ì´ë²„ ë¡œê·¸ì¸"""
        try:
            self.driver.get('https://nid.naver.com/nidlogin.login')
            time.sleep(2)
            
            # ID ì…ë ¥
            id_input = self.driver.find_element(By.ID, 'id')
            id_input.send_keys(os.getenv('NAVER_ID'))
            time.sleep(1)
            
            # PW ì…ë ¥
            pw_input = self.driver.find_element(By.ID, 'pw')
            pw_input.send_keys(os.getenv('NAVER_PW'))
            time.sleep(1)
            
            # ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­
            login_btn = self.driver.find_element(By.ID, 'log.login')
            login_btn.click()
            time.sleep(3)
            
            logging.info("âœ… ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ")
            return True
            
        except Exception as e:
            logging.error(f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def crawl_cafe(self, cafe_config: Dict) -> List[Dict]:
        """ì¹´í˜ ê²Œì‹œë¬¼ í¬ë¡¤ë§"""
        results = []
        
        try:
            # ì¹´í˜ ê²Œì‹œíŒ URLë¡œ ì´ë™
            board_url = f"{cafe_config['url']}/ArticleList.nhn?search.clubid={cafe_config['club_id']}&search.menuid={cafe_config['board_id']}"
            self.driver.get(board_url)
            time.sleep(3)
            
            # iframe ì „í™˜
            self.driver.switch_to.frame('cafe_main')
            time.sleep(1)
            
            # ê²Œì‹œë¬¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            articles = self.driver.find_elements(By.CSS_SELECTOR, 'div.article-board tr')
            
            for article in articles[:10]:  # ìµœì‹  10ê°œë§Œ
                try:
                    # ê³µì§€ì‚¬í•­ ì œì™¸
                    if 'board-notice' in article.get_attribute('class') or '':
                        continue
                    
                    # ì œëª©ê³¼ ë§í¬
                    title_elem = article.find_element(By.CSS_SELECTOR, 'a.article')
                    title = title_elem.text.strip()
                    link = title_elem.get_attribute('href')
                    
                    # ì‘ì„±ì
                    try:
                        author = article.find_element(By.CSS_SELECTOR, 'td.td_name a').text.strip()
                    except:
                        author = "Unknown"
                    
                    # ì‘ì„±ì¼
                    try:
                        date = article.find_element(By.CSS_SELECTOR, 'td.td_date').text.strip()
                    except:
                        date = datetime.now().strftime('%Y.%m.%d.')
                    
                    # ì¡°íšŒìˆ˜
                    try:
                        views = article.find_element(By.CSS_SELECTOR, 'td.td_view').text.strip()
                    except:
                        views = "0"
                    
                    # ê²Œì‹œë¬¼ ID ì¶”ì¶œ
                    article_id = link.split('articleid=')[-1].split('&')[0] if 'articleid=' in link else ""
                    
                    # ìƒì„¸ ë‚´ìš© í¬ë¡¤ë§
                    content = self.get_article_content(link)
                    
                    # ë°ì´í„° êµ¬ì„±
                    data = {
                        'title': title,
                        'author': author,
                        'date': date,
                        'views': views,
                        'url': link,
                        'article_id': article_id,
                        'content': content,
                        'cafe_name': cafe_config['name'],
                        'board_name': cafe_config['board_name'],
                        'crawled_at': datetime.now().isoformat(),
                        'hash': hashlib.md5(f"{title}{content}".encode()).hexdigest()
                    }
                    
                    results.append(data)
                    logging.info(f"ğŸ“„ í¬ë¡¤ë§: {title[:30]}...")
                    time.sleep(1)  # ìš”ì²­ ê°„ê²©
                    
                except Exception as e:
                    logging.error(f"ê²Œì‹œë¬¼ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
                    continue
            
            self.driver.switch_to.default_content()
            
        except Exception as e:
            logging.error(f"ì¹´í˜ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        
        return results
    
    def get_article_content(self, url: str) -> str:
        """ê²Œì‹œë¬¼ ìƒì„¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ìƒˆ íƒ­ì—ì„œ ì—´ê¸°
            self.driver.execute_script(f"window.open('{url}', '_blank');")
            self.driver.switch_to.window(self.driver.window_handles[-1])
            time.sleep(2)
            
            # iframe ì „í™˜
            self.driver.switch_to.frame('cafe_main')
            
            # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
            content = ""
            try:
                content_elem = self.driver.find_element(By.CSS_SELECTOR, 'div.se-main-container, div.content-box')
                content = content_elem.text.strip()
            except:
                try:
                    content_elem = self.driver.find_element(By.CSS_SELECTOR, 'div#tbody')
                    content = content_elem.text.strip()
                except:
                    content = ""
            
            # íƒ­ ë‹«ê¸°
            self.driver.close()
            self.driver.switch_to.window(self.driver.window_handles[0])
            
            return content[:2000]  # ë…¸ì…˜ ì œí•œ
            
        except Exception as e:
            logging.error(f"ë‚´ìš© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return ""
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            logging.info("âœ… ë“œë¼ì´ë²„ ì¢…ë£Œ")


class NotionDatabase:
    """ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        self.client = Client(auth=os.getenv('NOTION_TOKEN'))
        self.database_id = os.getenv('NOTION_DATABASE_ID')
    
    def check_duplicate(self, hash_value: str) -> bool:
        """ì¤‘ë³µ ì²´í¬"""
        try:
            response = self.client.databases.query(
                database_id=self.database_id,
                filter={
                    "property": "í•´ì‹œ",
                    "rich_text": {
                        "contains": hash_value
                    }
                }
            )
            return len(response['results']) > 0
        except:
            return False
    
    def save_article(self, article: Dict) -> bool:
        """ê²Œì‹œë¬¼ ì €ì¥"""
        try:
            # ì¤‘ë³µ ì²´í¬
            if self.check_duplicate(article['hash']):
                logging.info(f"â­ï¸ ì¤‘ë³µ ê²Œì‹œë¬¼ ê±´ë„ˆë›°ê¸°: {article['title'][:30]}...")
                return False
            
            # ë…¸ì…˜ í˜ì´ì§€ ìƒì„±
            page = self.client.pages.create(
                parent={"database_id": self.database_id},
                properties={
                    "ì œëª©": {
                        "title": [{"text": {"content": article['title']}}]
                    },
                    "URL": {
                        "url": article['url']
                    },
                    "ì‘ì„±ì": {
                        "rich_text": [{"text": {"content": article['author']}}]
                    },
                    "ì‘ì„±ì¼": {
                        "date": {"start": article['date']}
                    },
                    "ì¹´í˜ëª…": {
                        "select": {"name": article['cafe_name']}
                    },
                    "ë‚´ìš©": {
                        "rich_text": [{"text": {"content": article['content'][:2000]}}]
                    },
                    "í¬ë¡¤ë§ ì¼ì‹œ": {
                        "date": {"start": article['crawled_at']}
                    },
                    "ì¡°íšŒìˆ˜": {
                        "number": int(article.get('views', 0))
                    },
                    "ê²Œì‹œë¬¼ ID": {
                        "rich_text": [{"text": {"content": article.get('article_id', '')}}]
                    },
                    "í•´ì‹œ": {
                        "rich_text": [{"text": {"content": article['hash']}}]
                    },
                    "uploaded": {
                        "checkbox": False
                    }
                }
            )
            
            logging.info(f"âœ… ë…¸ì…˜ ì €ì¥ ì„±ê³µ: {article['title'][:30]}...")
            return True
            
        except Exception as e:
            logging.error(f"âŒ ë…¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logging.info("="*60)
    logging.info("ğŸš€ ë„¤ì´ë²„ ì¹´í˜ -> ë…¸ì…˜ í¬ë¡¤ë§ ì‹œì‘")
    logging.info(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now()}")
    logging.info("="*60)
    
    # ì¹´í˜ ì„¤ì • (2ê³³)
    cafes = [
        {
            'name': os.getenv('CAFE1_NAME', 'ì¹´í˜1'),
            'url': os.getenv('CAFE1_URL'),
            'club_id': os.getenv('CAFE1_CLUB_ID'),
            'board_id': os.getenv('CAFE1_BOARD_ID'),
            'board_name': os.getenv('CAFE1_BOARD_NAME', 'ê²Œì‹œíŒ')
        },
        {
            'name': os.getenv('CAFE2_NAME', 'ì¹´í˜2'),
            'url': os.getenv('CAFE2_URL'),
            'club_id': os.getenv('CAFE2_CLUB_ID'),
            'board_id': os.getenv('CAFE2_BOARD_ID'),
            'board_name': os.getenv('CAFE2_BOARD_NAME', 'ê²Œì‹œíŒ')
        }
    ]
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = NaverCafeCrawler()
    notion = NotionDatabase()
    
    try:
        # ë„¤ì´ë²„ ë¡œê·¸ì¸
        if not crawler.login_naver():
            raise Exception("ë¡œê·¸ì¸ ì‹¤íŒ¨")
        
        total_saved = 0
        
        # ê° ì¹´í˜ í¬ë¡¤ë§
        for cafe in cafes:
            logging.info(f"\nğŸ“ {cafe['name']} í¬ë¡¤ë§ ì‹œì‘...")
            articles = crawler.crawl_cafe(cafe)
            
            # ë…¸ì…˜ì— ì €ì¥
            for article in articles:
                if notion.save_article(article):
                    total_saved += 1
            
            logging.info(f"âœ… {cafe['name']}: {len(articles)}ê°œ í¬ë¡¤ë§, {total_saved}ê°œ ì €ì¥")
            time.sleep(2)
        
        logging.info(f"\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {total_saved}ê°œ ìƒˆ ê²Œì‹œë¬¼ ì €ì¥")
        
    except Exception as e:
        logging.error(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    finally:
        crawler.close()


if __name__ == "__main__":
    main()