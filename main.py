#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ë§ -> ë…¸ì…˜ ì €ì¥ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
ë§¤ì¼ ì •ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ ìƒˆ ê²Œì‹œë¬¼ì„ í¬ë¡¤ë§í•˜ê³  ë…¸ì…˜ì— ì €ì¥
"""

import os
import sys
import json
import time
import logging
from datetime import datetime, timedelta
from typing import List, Dict
from dotenv import load_dotenv
import hashlib

# Selenium imports
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service

# Notion imports
from notion_client import Client

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('crawler.log', encoding='utf-8')
    ]
)

class NaverCafeCrawler:
    """ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.driver = None
        self.wait = None
        self.setup_driver()
        
    def setup_driver(self):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì •"""
        options = Options()
        
        # GitHub Actions í™˜ê²½ì—ì„œëŠ” í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í•„ìˆ˜
        if os.getenv('GITHUB_ACTIONS'):
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
        
        # ê¸°ë³¸ ì˜µì…˜
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        try:
            self.driver = webdriver.Chrome(options=options)
            self.wait = WebDriverWait(self.driver, 10)
            logging.info("âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logging.error(f"âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def login_naver(self):
        """ë„¤ì´ë²„ ë¡œê·¸ì¸"""
        try:
            self.driver.get('https://nid.naver.com/nidlogin.login')
            time.sleep(2)
            
            # ID ì…ë ¥
            id_input = self.driver.find_element(By.ID, 'id')
            id_input.send_keys(os.getenv('NAVER_ID'))
            time.sleep(1)
            
            # PW ì…ë ¥
            pw_input = self.driver.find_element(By.ID, 'pw')
            pw_input.send_keys(os.getenv('NAVER_PW'))
            time.sleep(1)
            
            # ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­
            login_btn = self.driver.find_element(By.ID, 'log.login')
            login_btn.click()
            time.sleep(5)  # ë¡œê·¸ì¸ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
            
            logging.info("âœ… ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ")
            return True
            
        except Exception as e:
            logging.error(f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def crawl_cafe(self, cafe_config: Dict) -> List[Dict]:
        """ì¹´í˜ ê²Œì‹œë¬¼ í¬ë¡¤ë§"""
        results = []
        
        try:
            # URL ê²€ì¦
            if not cafe_config.get('url') or not cafe_config.get('club_id') or not cafe_config.get('board_id'):
                logging.error(f"ì¹´í˜ ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {cafe_config}")
                return results
            
            # ì¹´í˜ ê²Œì‹œíŒ URLë¡œ ì´ë™
            board_url = f"{cafe_config['url']}/ArticleList.nhn?search.clubid={cafe_config['club_id']}&search.menuid={cafe_config['board_id']}"
            logging.info(f"ğŸ“ URL ì ‘ì†: {board_url}")
            self.driver.get(board_url)
            time.sleep(3)
            
            # iframe ì „í™˜
            try:
                self.driver.switch_to.frame('cafe_main')
                time.sleep(1)
            except:
                logging.warning("iframe ì „í™˜ ì‹¤íŒ¨, ì§ì ‘ ì ‘ê·¼ ì‹œë„")
            
            # ì—¬ëŸ¬ ì„ íƒì ì‹œë„ (ë„¤ì´ë²„ ì¹´í˜ êµ¬ì¡°ê°€ ë‹¤ì–‘í•¨)
            selectors = [
                'div.article-board table tbody tr',  # êµ¬í˜• ì¹´í˜
                'ul.article-movie-sub li',  # ì˜í™”í˜•
                'div.ArticleListItem',  # ìƒˆí˜• ì¹´í˜
                'tr[class*="board-list"]',  # ì¼ë°˜ ë¦¬ìŠ¤íŠ¸
                'div.inner_list > a'  # ëª¨ë°”ì¼í˜•
            ]
            
            articles = []
            for selector in selectors:
                try:
                    articles = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if articles:
                        logging.info(f"âœ… ê²Œì‹œë¬¼ ë°œê²¬: {selector} ({len(articles)}ê°œ)")
                        break
                except:
                    continue
            
            if not articles:
                logging.warning("âŒ ê²Œì‹œë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HTML êµ¬ì¡° í™•ì¸ í•„ìš”")
                # HTML ë””ë²„ê¹… ì •ë³´
                try:
                    page_source = self.driver.page_source[:500]
                    logging.debug(f"Page HTML: {page_source}")
                except:
                    pass
                return results
            
            # ì‹¤ì œ ê²Œì‹œë¬¼ë§Œ í•„í„°ë§ (ê³µì§€ì‚¬í•­ ì œì™¸)
            actual_articles = []
            for article in articles:
                try:
                    # ê³µì§€ì‚¬í•­ í´ë˜ìŠ¤ ì²´í¬
                    class_attr = article.get_attribute('class') or ''
                    if 'notice' in class_attr.lower() or 'ê³µì§€' in class_attr:
                        continue
                    actual_articles.append(article)
                except:
                    actual_articles.append(article)
            
            logging.info(f"ğŸ“Š ê³µì§€ ì œì™¸ ì‹¤ì œ ê²Œì‹œë¬¼: {len(actual_articles)}ê°œ")
            
            # ìµœëŒ€ 4ê°œì”©ë§Œ ì²˜ë¦¬
            max_articles = 4
            processed_count = 0
            
            for idx, article in enumerate(actual_articles[:10], 1):  # ìµœì‹  10ê°œ ì¤‘ì—ì„œ
                if processed_count >= max_articles:
                    logging.info(f"âœ… ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜({max_articles}ê°œ) ë„ë‹¬")
                    break
                    
                try:
                    logging.debug(f"ì²˜ë¦¬ ì¤‘: {processed_count + 1}/{max_articles}")
                    
                    # ì œëª© ì°¾ê¸° (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
                    title = ""
                    link = ""
                    
                    # ë°©ë²• 1: a.article
                    try:
                        title_elem = article.find_element(By.CSS_SELECTOR, 'a.article')
                        title = title_elem.text.strip()
                        link = title_elem.get_attribute('href')
                    except:
                        pass
                    
                    # ë°©ë²• 2: td.td_article
                    if not title:
                        try:
                            title_elem = article.find_element(By.CSS_SELECTOR, 'td.td_article a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            pass
                    
                    # ë°©ë²• 3: class="inner_list"
                    if not title:
                        try:
                            title_elem = article.find_element(By.CSS_SELECTOR, '.inner_list a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            pass
                    
                    # ë°©ë²• 4: ì§ì ‘ a íƒœê·¸
                    if not title:
                        try:
                            title_elem = article.find_element(By.TAG_NAME, 'a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            continue
                    
                    if not title or not link:
                        continue
                    
                    # ê³µì§€ì‚¬í•­ ì œì™¸
                    if 'ê³µì§€' in title or 'notice' in str(article.get_attribute('class')):
                        continue
                    
                    # ì‘ì„±ì
                    author = "Unknown"
                    for author_selector in ['td.td_name a', '.td_name', '.nick', '.p-nick']:
                        try:
                            author = article.find_element(By.CSS_SELECTOR, author_selector).text.strip()
                            if author:
                                break
                        except:
                            pass
                    
                    # ì‘ì„±ì¼
                    date_str = ""
                    for date_selector in ['td.td_date', '.td_date', '.date']:
                        try:
                            date_str = article.find_element(By.CSS_SELECTOR, date_selector).text.strip()
                            if date_str:
                                break
                        except:
                            pass
                    
                    # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (YYYY.MM.DD. â†’ YYYY-MM-DD)
                    if date_str:
                        # "2025.08.25." í˜•ì‹ì„ "2025-08-25"ë¡œ ë³€í™˜
                        date_str = date_str.replace('.', '-').rstrip('-')
                        if len(date_str.split('-')) == 3:
                            year, month, day = date_str.split('-')
                            # 2ìë¦¬ ì—°ë„ ì²˜ë¦¬
                            if len(year) == 2:
                                year = '20' + year
                            date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                        else:
                            date = datetime.now().strftime('%Y-%m-%d')
                    else:
                        date = datetime.now().strftime('%Y-%m-%d')
                    
                    # ì¡°íšŒìˆ˜
                    views = "0"
                    for view_selector in ['td.td_view', '.td_view', '.view']:
                        try:
                            views = article.find_element(By.CSS_SELECTOR, view_selector).text.strip()
                            if views:
                                break
                        except:
                            pass
                    
                    # ê²Œì‹œë¬¼ ID ì¶”ì¶œ
                    article_id = link.split('articleid=')[-1].split('&')[0] if 'articleid=' in link else ""
                    
                    # URLë¡œ ì¤‘ë³µ ì²´í¬ (í¬ë¡¤ë§ ì „ì— í™•ì¸)
                    if link:
                        # ì´ë¯¸ ë…¸ì…˜ì— ìˆëŠ”ì§€ ë¨¼ì € ì²´í¬
                        try:
                            notion_check = NotionDatabase()
                            if notion_check.check_duplicate(link):
                                logging.info(f"â­ï¸ ì´ë¯¸ ì €ì¥ëœ ê²Œì‹œë¬¼: {title[:30]}...")
                                continue
                        except:
                            pass
                    
                    # ìƒì„¸ ë‚´ìš© í¬ë¡¤ë§
                    content = self.get_article_content(link)
                    
                    # ë°ì´í„° êµ¬ì„±
                    data = {
                        'title': title,
                        'author': author,
                        'date': date,
                        'views': views,
                        'url': link,
                        'article_id': article_id,
                        'content': content,
                        'cafe_name': cafe_config['name'],
                        'board_name': cafe_config['board_name'],
                        'crawled_at': datetime.now().isoformat(),
                        'hash': hashlib.md5(f"{title}{link}".encode()).hexdigest()
                    }
                    
                    results.append(data)
                    processed_count += 1
                    logging.info(f"ğŸ“„ [{processed_count:02d}/{max_articles}] í¬ë¡¤ë§: {title[:30]}...")
                    
                    # ìš”ì²­ ê°„ê²©
                    time.sleep(1)
                    
                except Exception as e:
                    logging.error(f"ê²Œì‹œë¬¼ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
                    continue
            
            self.driver.switch_to.default_content()
            
        except Exception as e:
            logging.error(f"ì¹´í˜ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        
        return results
    
    def get_article_content(self, url: str) -> str:
        """ê²Œì‹œë¬¼ ìƒì„¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ìƒˆ íƒ­ì—ì„œ ì—´ê¸°
            self.driver.execute_script(f"window.open('{url}', '_blank');")
            self.driver.switch_to.window(self.driver.window_handles[-1])
            time.sleep(2)
            
            # iframe ì „í™˜
            self.driver.switch_to.frame('cafe_main')
            
            # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
            content = ""
            try:
                content_elem = self.driver.find_element(By.CSS_SELECTOR, 'div.se-main-container, div.content-box')
                content = content_elem.text.strip()
            except:
                try:
                    content_elem = self.driver.find_element(By.CSS_SELECTOR, 'div#tbody')
                    content = content_elem.text.strip()
                except:
                    content = ""
            
            # íƒ­ ë‹«ê¸°
            self.driver.close()
            self.driver.switch_to.window(self.driver.window_handles[0])
            
            return content[:2000]  # ë…¸ì…˜ ì œí•œ
            
        except Exception as e:
            logging.error(f"ë‚´ìš© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return ""
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            logging.info("âœ… ë“œë¼ì´ë²„ ì¢…ë£Œ")


class NotionDatabase:
    """ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        self.client = Client(auth=os.getenv('NOTION_TOKEN'))
        self.database_id = os.getenv('NOTION_DATABASE_ID')
    
    def check_duplicate(self, hash_value: str) -> bool:
        """ì¤‘ë³µ ì²´í¬"""
        try:
            # í•´ì‹œ í•„ë“œê°€ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ URLë¡œ ì¤‘ë³µ ì²´í¬
            response = self.client.databases.query(
                database_id=self.database_id,
                filter={
                    "or": [
                        {
                            "property": "URL",
                            "url": {
                                "contains": hash_value[:20]  # URL ì¼ë¶€ë¡œ ì²´í¬
                            }
                        }
                    ]
                }
            )
            return len(response['results']) > 0
        except Exception as e:
            logging.debug(f"ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨: {e}")
            return False
    
    def save_article(self, article: Dict) -> bool:
        """ê²Œì‹œë¬¼ ì €ì¥"""
        try:
            # URLë¡œ ì¤‘ë³µ ì²´í¬
            if self.check_duplicate(article['url']):
                logging.info(f"â­ï¸ ì¤‘ë³µ ê²Œì‹œë¬¼ ê±´ë„ˆë›°ê¸°: {article['title'][:30]}...")
                return False
            
            # ë…¸ì…˜ DBì˜ ì‹¤ì œ í•„ë“œì— ë§ì¶°ì„œ ì €ì¥
            properties = {
                "í•˜ìœ—íŠ¸ ì–´ì›Œë“œ íŒë§¤(ìŠ¤ìœ„íŠ¸,Goh,í´ëŸ½)": {  # ì œëª© í•„ë“œ
                    "title": [{"text": {"content": article['title']}}]
                },
                "URL": {
                    "url": article['url']
                }
            }
            
            # ì„ íƒì  í•„ë“œë“¤ (ìˆìœ¼ë©´ ì¶”ê°€)
            if article.get('author'):
                properties["ì‘ì„±ì"] = {
                    "rich_text": [{"text": {"content": article['author']}}]
                }
            
            if article.get('date'):
                properties["ì‘ì„±ì¼"] = {
                    "date": {"start": article['date']}
                }
            
            if article.get('cafe_name'):
                properties["ì¹´í˜ëª…"] = {
                    "select": {"name": article['cafe_name']}
                }
            
            # ë‚´ìš© í•„ë“œ ì²˜ë¦¬
            content = article.get('content', '')[:2000]
            if content:
                properties["ë‚´ìš©"] = {
                    "rich_text": [{"text": {"content": content}}]
                }
            
            # í¬ë¡¤ë§ ì¼ì‹œ
            properties["í¬ë¡¤ë§ ì¼ì‹œ"] = {
                "date": {"start": datetime.now().isoformat()}
            }
            
            # uploaded ì²´í¬ë°•ìŠ¤
            properties["uploaded"] = {
                "checkbox": False
            }
            
            # ë…¸ì…˜ í˜ì´ì§€ ìƒì„±
            page = self.client.pages.create(
                parent={"database_id": self.database_id},
                properties=properties
            )
            
            logging.info(f"âœ… ë…¸ì…˜ ì €ì¥ ì„±ê³µ: {article['title'][:30]}...")
            return True
            
        except Exception as e:
            logging.error(f"âŒ ë…¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logging.info("="*60)
    logging.info("ğŸš€ ë„¤ì´ë²„ ì¹´í˜ -> ë…¸ì…˜ í¬ë¡¤ë§ ì‹œì‘")
    logging.info(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now()}")
    logging.info("="*60)
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    required_env = ['NAVER_ID', 'NAVER_PW', 'NOTION_TOKEN', 'NOTION_DATABASE_ID']
    missing_env = [env for env in required_env if not os.getenv(env)]
    
    if missing_env:
        logging.error(f"âŒ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_env)}")
        logging.error("GitHub Secretsë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        sys.exit(1)
    
    # ì¹´í˜ ì„¤ì • (2ê³³)
    cafes = []
    
    # ì¹´í˜ 1 ì„¤ì • í™•ì¸
    if os.getenv('CAFE1_URL') and os.getenv('CAFE1_CLUB_ID') and os.getenv('CAFE1_BOARD_ID'):
        cafes.append({
            'name': os.getenv('CAFE1_NAME', 'ì¹´í˜1'),
            'url': os.getenv('CAFE1_URL'),
            'club_id': os.getenv('CAFE1_CLUB_ID'),
            'board_id': os.getenv('CAFE1_BOARD_ID'),
            'board_name': os.getenv('CAFE1_BOARD_NAME', 'ê²Œì‹œíŒ')
        })
    
    # ì¹´í˜ 2 ì„¤ì • í™•ì¸
    if os.getenv('CAFE2_URL') and os.getenv('CAFE2_CLUB_ID') and os.getenv('CAFE2_BOARD_ID'):
        cafes.append({
            'name': os.getenv('CAFE2_NAME', 'ì¹´í˜2'),
            'url': os.getenv('CAFE2_URL'),
            'club_id': os.getenv('CAFE2_CLUB_ID'),
            'board_id': os.getenv('CAFE2_BOARD_ID'),
            'board_name': os.getenv('CAFE2_BOARD_NAME', 'ê²Œì‹œíŒ')
        })
    
    if not cafes:
        logging.error("âŒ í¬ë¡¤ë§í•  ì¹´í˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        logging.error("ìµœì†Œ 1ê°œ ì´ìƒì˜ ì¹´í˜ ì •ë³´ë¥¼ GitHub Secretsì— ì„¤ì •í•´ì£¼ì„¸ìš”:")
        logging.error("CAFE1_URL, CAFE1_CLUB_ID, CAFE1_BOARD_ID")
        sys.exit(1)
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = NaverCafeCrawler()
    notion = NotionDatabase()
    
    try:
        # ë„¤ì´ë²„ ë¡œê·¸ì¸
        if not crawler.login_naver():
            raise Exception("ë¡œê·¸ì¸ ì‹¤íŒ¨")
        
        total_saved = 0
        
        # ê° ì¹´í˜ í¬ë¡¤ë§
        for cafe in cafes:
            logging.info(f"\nğŸ“ {cafe['name']} í¬ë¡¤ë§ ì‹œì‘...")
            articles = crawler.crawl_cafe(cafe)
            
            # ë…¸ì…˜ì— ì €ì¥
            cafe_saved = 0
            for article in articles:
                if notion.save_article(article):
                    cafe_saved += 1
                    total_saved += 1
            
            logging.info(f"âœ… {cafe['name']}: {len(articles)}ê°œ í¬ë¡¤ë§, {cafe_saved}ê°œ ìƒˆë¡œ ì €ì¥")
            time.sleep(2)
        
        logging.info(f"\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {total_saved}ê°œ ìƒˆ ê²Œì‹œë¬¼ ì €ì¥")
        
    except Exception as e:
        logging.error(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    finally:
        crawler.close()


if __name__ == "__main__":
    main()