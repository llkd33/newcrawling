#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ë§ -> ë…¸ì…˜ ì €ì¥ (ìµœì¢… ìˆ˜ì • ë²„ì „)
ë‚´ìš© ì¶”ì¶œ ë¬¸ì œ ì™„ì „ í•´ê²°
"""

import os
import sys
import time
import logging
from datetime import datetime
import re
from typing import List, Dict
from dotenv import load_dotenv
import hashlib

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from notion_client import Client

# ìƒˆë¡œìš´ ì½˜í…ì¸  ì¶”ì¶œ ì‹œìŠ¤í…œ import
from content_extractor import ContentExtractor
from content_extraction_models import ExtractionConfig

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('crawler.log', encoding='utf-8')
    ]
)

class NaverCafeCrawler:
    """ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.driver = None
        self.wait = None
        self.content_extractor = None
        self.setup_driver()
        
    def setup_driver(self):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì •"""
        options = Options()
        
        # GitHub Actions í™˜ê²½
        if os.getenv('GITHUB_ACTIONS'):
            # Use new headless for better JS rendering in CI
            options.add_argument('--headless=new')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
        
        # ê¸°ë³¸ ì˜µì…˜
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        try:
            self.driver = webdriver.Chrome(options=options)
            self.wait = WebDriverWait(self.driver, 15)
            
            # ìƒˆë¡œìš´ ì½˜í…ì¸  ì¶”ì¶œê¸° ì´ˆê¸°í™”
            extraction_config = ExtractionConfig(
                timeout_seconds=int(os.getenv('CONTENT_EXTRACTION_TIMEOUT', '30')),
                min_content_length=int(os.getenv('CONTENT_MIN_LENGTH', '30')),
                max_content_length=int(os.getenv('CONTENT_MAX_LENGTH', '2000')),
                retry_count=int(os.getenv('EXTRACTION_RETRY_COUNT', '3')),
                enable_debug_screenshot=os.getenv('DEBUG_SCREENSHOT_ENABLED', 'true').lower() == 'true'
            )
            
            self.content_extractor = ContentExtractor(self.driver, self.wait, extraction_config)
            
            logging.info("âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ë° ì½˜í…ì¸  ì¶”ì¶œê¸° ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logging.error(f"âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def login_naver(self):
        """ë„¤ì´ë²„ ë¡œê·¸ì¸"""
        try:
            # ìë™í™” íƒì§€ ìš°íšŒ
            self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                '''
            })
            
            self.driver.get('https://nid.naver.com/nidlogin.login')
            time.sleep(3)
            
            # ID/PW ì…ë ¥
            id_input = self.driver.find_element(By.ID, 'id')
            pw_input = self.driver.find_element(By.ID, 'pw')
            
            self.driver.execute_script("""
                arguments[0].value = arguments[1];
                arguments[0].dispatchEvent(new Event('input', { bubbles: true }));
            """, id_input, os.getenv('NAVER_ID'))
            
            time.sleep(1)
            
            self.driver.execute_script("""
                arguments[0].value = arguments[1];
                arguments[0].dispatchEvent(new Event('input', { bubbles: true }));
            """, pw_input, os.getenv('NAVER_PW'))
            
            time.sleep(1)
            
            # ë¡œê·¸ì¸ í´ë¦­
            login_btn = self.driver.find_element(By.ID, 'log.login')
            self.driver.execute_script("arguments[0].click();", login_btn)
            
            time.sleep(10)
            
            if any(x in self.driver.current_url for x in ['naver.com', 'main']):
                logging.info("âœ… ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ")
                return True
            else:
                logging.warning("âš ï¸ ë¡œê·¸ì¸ í™•ì¸ í•„ìš”")
                return True
                
        except Exception as e:
            logging.error(f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def get_article_content(self, url: str) -> str:
        """
        ê²Œì‹œë¬¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° - ìƒˆë¡œìš´ ContentExtractor ì‚¬ìš©
        ê¸°ì¡´ì˜ ë³µì¡í•œ ë¡œì§ì„ ëª¨ë“ˆí™”ëœ ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´
        """
        try:
            logging.info(f"ğŸ“– ìƒˆë¡œìš´ ContentExtractorë¡œ ë‚´ìš© ì¶”ì¶œ: {url}")
            
            # ìƒˆë¡œìš´ ContentExtractor ì‚¬ìš©
            result = self.content_extractor.extract_content(url)
            
            if result.success and result.content and len(result.content.strip()) > 50:
                # JavaScript ì˜¤ë¥˜ ë©”ì‹œì§€ ì²´í¬
                if "We're sorry but web-pc doesn't work properly" in result.content:
                    logging.warning("âš ï¸ JavaScript ì˜¤ë¥˜ ë©”ì‹œì§€ ê°ì§€, í´ë°± ì‹œë„")
                    return self._fallback_content_extraction(url)
                
                logging.info(f"âœ… ë‚´ìš© ì¶”ì¶œ ì„±ê³µ: {len(result.content)}ì (ë°©ë²•: {result.extraction_method.value}, í’ˆì§ˆ: {result.quality_score:.2f})")
                return result.content
            else:
                logging.warning(f"âš ï¸ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë‚´ìš© ë¶€ì¡±: {result.error_message}")
                return self._fallback_content_extraction(url)
                
        except Exception as e:
            logging.error(f"âŒ ContentExtractor ì‚¬ìš© ì¤‘ ì˜¤ë¥˜: {e}")
            return self._fallback_content_extraction(url)
    
    def _fallback_content_extraction(self, url: str) -> str:
        """í´ë°± ë‚´ìš© ì¶”ì¶œ ë°©ë²•"""
        try:
            logging.info(f"ğŸ”§ í´ë°± ë‚´ìš© ì¶”ì¶œ ì‹œë„: {url}")
            
            # í˜„ì¬ í˜ì´ì§€ë¡œ ì´ë™
            self.driver.get(url)
            time.sleep(5)
            
            # iframe ì „í™˜ ì‹œë„
            try:
                self.driver.switch_to.frame('cafe_main')
                time.sleep(3)
            except:
                pass
            
            # ë‹¤ì–‘í•œ ì„ íƒìë¡œ ë‚´ìš© ì¶”ì¶œ ì‹œë„
            content_selectors = [
                '.se-main-container',
                '.se-component',
                '#content-area',
                '.article_viewer',
                '.article-board-content',
                '.content_text',
                '.post-content',
                '.board-content'
            ]
            
            for selector in content_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        content = elements[0].text.strip()
                        if content and len(content) > 30:
                            logging.info(f"âœ… í´ë°± ì¶”ì¶œ ì„±ê³µ: {len(content)}ì (ì„ íƒì: {selector})")
                            return content
                except:
                    continue
            
            # ìµœí›„ ìˆ˜ë‹¨: body ì „ì²´ì—ì„œ ì¶”ì¶œ
            try:
                body = self.driver.find_element(By.TAG_NAME, 'body')
                content = body.text.strip()
                if content and len(content) > 100:
                    # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                    lines = content.split('\n')
                    filtered_lines = []
                    for line in lines:
                        line = line.strip()
                        if line and not any(skip in line.lower() for skip in ['javascript', 'cookie', 'privacy', 'terms']):
                            filtered_lines.append(line)
                    
                    filtered_content = '\n'.join(filtered_lines[:20])  # ì²˜ìŒ 20ì¤„ë§Œ
                    if len(filtered_content) > 50:
                        logging.info(f"âœ… ìµœí›„ ìˆ˜ë‹¨ ì¶”ì¶œ ì„±ê³µ: {len(filtered_content)}ì")
                        return filtered_content
            except:
                pass
            
            self.driver.switch_to.default_content()
            return f"[ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨]\n\nê²Œì‹œë¬¼ ë§í¬: {url}\n\nìˆ˜ë™ìœ¼ë¡œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
            
        except Exception as e:
            logging.error(f"âŒ í´ë°± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return f"[ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨]\n\nê²Œì‹œë¬¼ ë§í¬: {url}\n\nì˜¤ë¥˜: {str(e)}"
    
    def crawl_cafe(self, cafe_config: Dict) -> List[Dict]:
        """ì¹´í˜ ê²Œì‹œë¬¼ í¬ë¡¤ë§"""
        results = []
        
        try:
            # ì¹´í˜ ê²Œì‹œíŒ ì ‘ì† - F-E ì¹´í˜ URL êµ¬ì¡°ì— ë§ì¶¤
            if cafe_config['name'] == 'F-E ì¹´í˜':
                # F-E ì¹´í˜ ì „ìš© URL êµ¬ì¡°
                board_url = f"{cafe_config['url']}/cafes/{cafe_config['club_id']}/menus/{cafe_config['board_id']}?viewType=L"
            else:
                # ì¼ë°˜ ì¹´í˜ URL êµ¬ì¡°
                board_url = f"{cafe_config['url']}/ArticleList.nhn?search.clubid={cafe_config['club_id']}&search.menuid={cafe_config['board_id']}"
            logging.info(f"ğŸ“ URL ì ‘ì†: {board_url}")
            self.driver.get(board_url)
            time.sleep(5)
            
            # iframe ì „í™˜
            try:
                self.driver.switch_to.frame('cafe_main')
                time.sleep(2)
            except:
                logging.warning("iframe ì „í™˜ ì‹¤íŒ¨")
            
            # ê²Œì‹œë¬¼ ì°¾ê¸°
            articles = []
            selectors = [
                'div.article-board table tbody tr',
                'ul.article-movie-sub li',
                'div.ArticleListItem'
            ]
            
            for selector in selectors:
                try:
                    articles = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if articles:
                        logging.info(f"âœ… ê²Œì‹œë¬¼ ë°œê²¬: {len(articles)}ê°œ")
                        break
                except:
                    continue
            
            if not articles:
                logging.warning("ê²Œì‹œë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return results
            
            # ê³µì§€ ì œì™¸ (ì—¬ëŸ¬ íŒ¨í„´ ì²˜ë¦¬)
            actual_articles = []
            for article in articles:
                try:
                    is_notice = False
                    # í´ë˜ìŠ¤ ê¸°ë°˜
                    try:
                        cls = (article.get_attribute('class') or '').lower()
                        if 'notice' in cls:
                            is_notice = True
                    except:
                        pass

                    # ì‹œê°ì  ì•„ì´ì½˜/í‘œì‹œ ê¸°ë°˜
                    if not is_notice:
                        try:
                            if article.find_elements(By.CSS_SELECTOR, 'img[alt="ê³µì§€"], .notice, .icon_notice, .board-notice, .ArticleList__notice'):
                                is_notice = True
                        except:
                            pass

                    # ì…€ í…ìŠ¤íŠ¸ ê¸°ë°˜
                    if not is_notice:
                        try:
                            td_article_elems = article.find_elements(By.CSS_SELECTOR, 'td, th, .td_article')
                            for td in td_article_elems[:2]:
                                t = td.text.strip()
                                if t == 'ê³µì§€' or t.startswith('ê³µì§€') or '[ê³µì§€]' in t:
                                    is_notice = True
                                    break
                        except:
                            pass

                    # ì „ì²´ í…ìŠ¤íŠ¸ ê²€ì‚¬ (ìµœí›„ì˜ ìˆ˜ë‹¨)
                    if not is_notice:
                        text = (article.text or '').strip()
                        if not text or 'ê³µì§€' in text:
                            # ê³µë°±ì´ê±°ë‚˜ ê³µì§€ í¬í•¨ì´ë©´ ì œì™¸
                            if 'ê³µì§€' in text:
                                is_notice = True
                            else:
                                # ê³µë°±ì€ ì œì™¸í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰
                                pass

                    if is_notice:
                        continue
                    actual_articles.append(article)
                except:
                    # ì˜¤ë¥˜ ì‹œì—ëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ í¬í•¨
                    actual_articles.append(article)
            
            logging.info(f"ğŸ“Š ê³µì§€ ì œì™¸ ì‹¤ì œ ê²Œì‹œë¬¼: {len(actual_articles)}ê°œ")
            
            # ìµœëŒ€ 3ê°œ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„)
            max_articles = 3
            processed = 0
            
            for article in actual_articles[:20]:
                if processed >= max_articles:
                    break
                
                try:
                    # ì œëª©ê³¼ ë§í¬ - ë” ì •í™•í•œ ì„ íƒì ì‚¬ìš©
                    link_elem = None
                    title = ""
                    link = ""
                    
                    # F-E ì¹´í˜ì™€ ì¼ë°˜ ì¹´í˜ êµ¬ë¶„í•˜ì—¬ ì²˜ë¦¬
                    if cafe_config['name'] == 'F-E ì¹´í˜':
                        # F-E ì¹´í˜ ì „ìš© ì„ íƒì
                        try:
                            link_elem = article.find_element(By.CSS_SELECTOR, 'a[href*="articles"]')
                            title = link_elem.text.strip()
                            link = link_elem.get_attribute('href')
                        except:
                            try:
                                # ëŒ€ì²´ ì„ íƒì
                                link_elem = article.find_element(By.CSS_SELECTOR, 'a')
                                title = link_elem.text.strip()
                                link = link_elem.get_attribute('href')
                            except:
                                continue
                    else:
                        # ì¼ë°˜ ì¹´í˜ ì„ íƒì
                        for sel in ['a.article', 'td.td_article a', 'a[href*="articleid"]', 'a']:
                            try:
                                link_elem = article.find_element(By.CSS_SELECTOR, sel)
                                title = link_elem.text.strip()
                                link = link_elem.get_attribute('href')
                                if link and ('articleid=' in link or 'articles/' in link):
                                    break
                            except:
                                continue
                    
                    # ìœ íš¨ì„± ê²€ì‚¬
                    if not title or not link or 'ê³µì§€' in title:
                        continue
                    
                    # URL ì •ë¦¬ (ì˜ëª»ëœ URL í˜•ì‹ ìˆ˜ì •)
                    if link.endswith('#'):
                        link = link[:-1]
                    
                    # ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
                    if link.startswith('/'):
                        link = 'https://cafe.naver.com' + link
                    
                    # ì¤‘ë³µ ì²´í¬ (ì„ì‹œ ë¹„í™œì„±í™” - í…ŒìŠ¤íŠ¸ìš©)
                    article_id = link.split('articleid=')[-1].split('&')[0] if 'articleid=' in link else ""
                    
                    # TODO: í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ì¤‘ë³µ ì²´í¬ ë‹¤ì‹œ í™œì„±í™”
                    # try:
                    #     notion = NotionDatabase()
                    #     if notion.check_duplicate(link):
                    #         logging.info(f"â­ï¸ ì´ë¯¸ ì €ì¥ë¨: {title[:30]}...")
                    #         continue
                    # except:
                    #     pass
                    
                    logging.info(f"ğŸ”„ ì¤‘ë³µ ì²´í¬ ë¹„í™œì„±í™” - ê°•ì œ ì²˜ë¦¬: {title[:30]}...")
                    
                    # ë‚´ìš© í¬ë¡¤ë§
                    logging.info(f"ğŸ“– í¬ë¡¤ë§ ì‹œì‘: {title[:30]}...")
                    logging.info(f"ğŸ”— URL: {link}")
                    
                    content = self.get_article_content(link)
                    
                    logging.info(f"ğŸ“ ì¶”ì¶œëœ ë‚´ìš© ê¸¸ì´: {len(content)}ì")
                    logging.info(f"ğŸ“„ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content[:100]}...")

                    # ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ í›„ ì €ì¥
                    if "ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in content:
                        logging.warning(f"âš ï¸ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨, ì œëª©ê³¼ ë§í¬ë§Œ ì €ì¥: {title[:30]}...")
                        content = f"[ë‚´ìš© ìë™ ì¶”ì¶œ ì‹¤íŒ¨]\n\nì œëª©: {title}\n\nì›ë³¸ ê²Œì‹œê¸€ì„ í™•ì¸í•˜ë ¤ë©´ URLì„ í´ë¦­í•˜ì„¸ìš”."
                    else:
                        logging.info(f"âœ… ë‚´ìš© ì¶”ì¶œ ì„±ê³µ: {title[:30]}...")
                    
                    # ì‘ì„±ì
                    author = "Unknown"
                    try:
                        author = article.find_element(By.CSS_SELECTOR, 'td.td_name').text.strip()
                    except:
                        pass
                    
                    # ì‘ì„±ì¼
                    date_str = datetime.now().strftime('%Y-%m-%d')
                    try:
                        date_elem = article.find_element(By.CSS_SELECTOR, 'td.td_date')
                        date_str = date_elem.text.replace('.', '-').rstrip('-')
                    except:
                        pass
                    
                    # ë°ì´í„° êµ¬ì„±
                    data = {
                        'title': title,
                        'author': author,
                        'date': date_str,
                        'url': link,
                        'article_id': article_id,
                        'content': content,
                        'cafe_name': cafe_config['name'],
                        'crawled_at': datetime.now().isoformat()
                    }
                    
                    results.append(data)
                    processed += 1
                    logging.info(f"âœ… [{processed}/{max_articles}] ì™„ë£Œ")
                    
                    time.sleep(2)
                    
                except Exception as e:
                    logging.error(f"ê²Œì‹œë¬¼ ì˜¤ë¥˜: {e}")
                    continue
            
            self.driver.switch_to.default_content()
            
        except Exception as e:
            logging.error(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        
        return results
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            logging.info("âœ… ë“œë¼ì´ë²„ ì¢…ë£Œ")


class NotionDatabase:
    """ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤"""
    
    def __init__(self):
        self.client = Client(auth=os.getenv('NOTION_TOKEN'))
        self.database_id = os.getenv('NOTION_DATABASE_ID')
    
    def check_duplicate(self, url: str) -> bool:
        """ì¤‘ë³µ ì²´í¬ - URL í•„ë“œ ê¸°ë°˜"""
        try:
            logging.debug(f"ğŸ” ì¤‘ë³µ ì²´í¬: {url}")
            
            # URLë¡œ ì¤‘ë³µ ì²´í¬
            query_filter = {
                "property": "URL",
                "url": {"equals": url}
            }

            response = self.client.databases.query(
                database_id=self.database_id,
                filter=query_filter
            )
            
            num_results = len(response.get('results', []))
            is_duplicate = num_results > 0
            
            if is_duplicate:
                logging.debug(f"  ğŸ”´ ì¤‘ë³µ ë°œê²¬: {num_results}ê°œ")
            else:
                logging.debug(f"  ğŸŸ¢ ìƒˆë¡œìš´ ê²Œì‹œë¬¼")
            
            return is_duplicate

        except Exception as e:
            logging.error(f"âŒ ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œì—ëŠ” ì¤‘ë³µì´ ì•„ë‹ˆë¼ê³  íŒë‹¨ (ì•ˆì „ì¥ì¹˜)
            return False
    
    def save_article(self, article: Dict) -> bool:
        """ê²Œì‹œë¬¼ ì €ì¥ - ë…¸ì…˜ DB êµ¬ì¡°ì— ë§ì¶¤"""
        try:
            # TODO: í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ì¤‘ë³µ ì²´í¬ ë‹¤ì‹œ í™œì„±í™”
            # if self.check_duplicate(article['url']):
            #     logging.info(f"â­ï¸ ì¤‘ë³µ: {article['title'][:30]}...")
            #     return False
            
            logging.info(f"ğŸ’¾ ì¤‘ë³µ ì²´í¬ ë¹„í™œì„±í™” - ê°•ì œ ì €ì¥ ì‹œë„: {article['title'][:30]}...")
            
            # ë…¸ì…˜ ì†ì„± (ì •í™•í•œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ì— ë§ì¶¤)
            properties = {}
            
            # 1. ì œëª© - Title í•„ë“œ
            title = article.get('title', '').strip() or "ì œëª© ì—†ìŒ"
            if len(title) > 100:
                title = title[:97] + "..."
            
            properties["ì œëª©"] = {
                "title": [{"text": {"content": title}}]
            }
            
            # 2. ì‘ì„±ì - Text í•„ë“œ
            author = article.get('author', 'Unknown').strip()
            properties["ì‘ì„±ì"] = {
                "rich_text": [{"text": {"content": author}}]
            }
            
            # 3. ì‘ì„±ì¼ - Text í•„ë“œ
            date_str = article.get('date', datetime.now().strftime('%Y-%m-%d'))
            properties["ì‘ì„±ì¼"] = {
                "rich_text": [{"text": {"content": date_str}}]
            }
            
            # 4. URL - URL í•„ë“œ
            if article.get('url'):
                properties["URL"] = {"url": article['url']}
            
            # 5. ë‚´ìš© - Text í•„ë“œ
            content = article.get('content', '').strip()
            if not content:
                content = "[ë‚´ìš© ì—†ìŒ]"
            
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (ë…¸ì…˜ Rich Text ì œí•œ ê³ ë ¤)
            if len(content) > 2000:
                content = content[:1997] + "..."
            
            properties["ë‚´ìš©"] = {
                "rich_text": [{"text": {"content": content}}]
            }
            
            # 6. í¬ë¡¤ë§ ì¼ì‹œ - ë‚ ì§œ í•„ë“œ (í˜„ì¬ ì‹œê°„)
            properties["í¬ë¡¤ë§ ì¼ì‹œ"] = {
                "date": {"start": datetime.now().isoformat()}
            }
            
            # 7. ì¹´í˜ëª… - Select í•„ë“œ
            cafe_name = article.get('cafe_name', 'Unknown')
            properties["ì¹´í˜ëª…"] = {
                "select": {"name": cafe_name}
            }
            
            # 8. uploaded - Checkbox í•„ë“œ (ê¸°ë³¸ê°’: false)
            properties["uploaded"] = {"checkbox": False}
            
            # í˜ì´ì§€ ìƒì„±
            page = self.client.pages.create(
                parent={"database_id": self.database_id},
                properties=properties
            )
            
            logging.info(f"âœ… ë…¸ì…˜ ì €ì¥ ì„±ê³µ: {title[:30]}...")
            return True
            
        except Exception as e:
            logging.error(f"âŒ ë…¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")
            logging.error(f"   ê²Œì‹œë¬¼ ì •ë³´: {article.get('title', 'Unknown')[:50]}")
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´
            import traceback
            logging.debug(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return False


def main():
    """ë©”ì¸"""
    logging.info("="*60)
    logging.info("ğŸš€ ë„¤ì´ë²„ ì¹´í˜ â†’ ë…¸ì…˜ í¬ë¡¤ë§ ì‹œì‘")
    logging.info(f"â° {datetime.now()}")
    logging.info("="*60)
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    required = ['NAVER_ID', 'NAVER_PW', 'NOTION_TOKEN', 'NOTION_DATABASE_ID']
    missing = [e for e in required if not os.getenv(e)]
    
    if missing:
        logging.error(f"âŒ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing)}")
        sys.exit(1)
    
    # ì¹´í˜ ì„¤ì • - F-E ì¹´í˜ë§Œ í¬ë¡¤ë§
    cafes = []
    
    # F-E ì¹´í˜ ì„¤ì • (ì œê³µëœ ì •ë³´ ê¸°ë°˜)
    cafes.append({
        'name': 'F-E ì¹´í˜',
        'url': 'https://cafe.naver.com/f-e',
        'club_id': '18786605',
        'board_id': '105'
    })
    
    # ì¶”ê°€ ì¹´í˜ëŠ” í™˜ê²½ë³€ìˆ˜ê°€ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ ì¶”ê°€
    # í˜„ì¬ëŠ” F-E ì¹´í˜ë§Œ í¬ë¡¤ë§í•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
    # if os.getenv('CAFE1_URL') and os.getenv('CAFE1_CLUB_ID') and os.getenv('CAFE1_BOARD_ID'):
    #     cafes.append({
    #         'name': os.getenv('CAFE1_NAME', 'ì¹´í˜1'),
    #         'url': os.getenv('CAFE1_URL'),
    #         'club_id': os.getenv('CAFE1_CLUB_ID'),
    #         'board_id': os.getenv('CAFE1_BOARD_ID')
    #     })
    
    logging.info(f"ğŸ“‹ ì„¤ì •ëœ ì¹´í˜ ìˆ˜: {len(cafes)}ê°œ")
    for i, cafe in enumerate(cafes, 1):
        logging.info(f"  {i}. {cafe['name']} (ID: {cafe['club_id']}, Board: {cafe['board_id']})")
    
    if not cafes:
        logging.error("âŒ ì¹´í˜ ì„¤ì • ì—†ìŒ")
        sys.exit(1)
    
    # í¬ë¡¤ëŸ¬ ì‹¤í–‰
    crawler = NaverCafeCrawler()
    notion = NotionDatabase()
    
    try:
        if not crawler.login_naver():
            raise Exception("ë¡œê·¸ì¸ ì‹¤íŒ¨")
        
        total = 0
        
        for cafe in cafes:
            logging.info(f"\nğŸ“ {cafe['name']} í¬ë¡¤ë§...")
            articles = crawler.crawl_cafe(cafe)
            
            saved = 0
            for article in articles:
                if notion.save_article(article):
                    saved += 1
                    total += 1
            
            logging.info(f"âœ… {cafe['name']}: {saved}ê°œ ì €ì¥")
            time.sleep(2)
        
        logging.info(f"\nğŸ‰ ì™„ë£Œ! ì´ {total}ê°œ ì €ì¥")
        
    except Exception as e:
        logging.error(f"âŒ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    finally:
        crawler.close()


if __name__ == "__main__":
    main()
