#!/usr/bin/env python3
"""
ÎÑ§Ïù¥Î≤Ñ Ïπ¥Ìéò ÌÅ¨Î°§ÎßÅ -> ÎÖ∏ÏÖò Ï†ÄÏû• Î©îÏù∏ Ïä§ÌÅ¨Î¶ΩÌä∏
Îß§Ïùº Ï†ïÍ∏∞Ï†ÅÏúºÎ°ú Ïã§ÌñâÎêòÏñ¥ ÏÉà Í≤åÏãúÎ¨ºÏùÑ ÌÅ¨Î°§ÎßÅÌïòÍ≥† ÎÖ∏ÏÖòÏóê Ï†ÄÏû•
"""

import os
import sys
import json
import time
import logging
from datetime import datetime, timedelta
from typing import List, Dict
from dotenv import load_dotenv
import hashlib

# Selenium imports
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service

# Notion imports
from notion_client import Client

# ÌôòÍ≤ΩÎ≥ÄÏàò Î°úÎìú
load_dotenv()

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('crawler.log', encoding='utf-8')
    ]
)

class NaverCafeCrawler:
    """ÎÑ§Ïù¥Î≤Ñ Ïπ¥Ìéò ÌÅ¨Î°§Îü¨"""
    
    def __init__(self):
        self.driver = None
        self.wait = None
        self.setup_driver()
        
    def setup_driver(self):
        """Selenium ÎìúÎùºÏù¥Î≤Ñ ÏÑ§Ï†ï"""
        options = Options()
        
        # GitHub Actions ÌôòÍ≤ΩÏóêÏÑúÎäî Ìó§ÎìúÎ¶¨Ïä§ Î™®Îìú ÌïÑÏàò
        if os.getenv('GITHUB_ACTIONS'):
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
        
        # Í∏∞Î≥∏ ÏòµÏÖò
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        try:
            self.driver = webdriver.Chrome(options=options)
            self.wait = WebDriverWait(self.driver, 10)
            logging.info("‚úÖ ÌÅ¨Î°¨ ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî ÏÑ±Í≥µ")
        except Exception as e:
            logging.error(f"‚ùå ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            raise
    
    def login_naver(self):
        """ÎÑ§Ïù¥Î≤Ñ Î°úÍ∑∏Ïù∏"""
        try:
            self.driver.get('https://nid.naver.com/nidlogin.login')
            time.sleep(2)
            
            # ID ÏûÖÎ†•
            id_input = self.driver.find_element(By.ID, 'id')
            id_input.send_keys(os.getenv('NAVER_ID'))
            time.sleep(1)
            
            # PW ÏûÖÎ†•
            pw_input = self.driver.find_element(By.ID, 'pw')
            pw_input.send_keys(os.getenv('NAVER_PW'))
            time.sleep(1)
            
            # Î°úÍ∑∏Ïù∏ Î≤ÑÌäº ÌÅ¥Î¶≠
            login_btn = self.driver.find_element(By.ID, 'log.login')
            login_btn.click()
            time.sleep(5)  # Î°úÍ∑∏Ïù∏ ÎåÄÍ∏∞ ÏãúÍ∞Ñ Ï¶ùÍ∞Ä
            
            logging.info("‚úÖ ÎÑ§Ïù¥Î≤Ñ Î°úÍ∑∏Ïù∏ ÏÑ±Í≥µ")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå Î°úÍ∑∏Ïù∏ Ïã§Ìå®: {e}")
            return False
    
    def crawl_cafe(self, cafe_config: Dict) -> List[Dict]:
        """Ïπ¥Ìéò Í≤åÏãúÎ¨º ÌÅ¨Î°§ÎßÅ"""
        results = []
        
        try:
            # URL Í≤ÄÏ¶ù
            if not cafe_config.get('url') or not cafe_config.get('club_id') or not cafe_config.get('board_id'):
                logging.error(f"Ïπ¥Ìéò ÏÑ§Ï†ïÏù¥ Ïò¨Î∞îÎ•¥ÏßÄ ÏïäÏäµÎãàÎã§: {cafe_config}")
                return results
            
            # Ïπ¥Ìéò Í≤åÏãúÌåê URLÎ°ú Ïù¥Îèô
            board_url = f"{cafe_config['url']}/ArticleList.nhn?search.clubid={cafe_config['club_id']}&search.menuid={cafe_config['board_id']}"
            logging.info(f"üìç URL Ï†ëÏÜç: {board_url}")
            self.driver.get(board_url)
            time.sleep(3)
            
            # iframe Ï†ÑÌôò
            try:
                self.driver.switch_to.frame('cafe_main')
                time.sleep(1)
            except:
                logging.warning("iframe Ï†ÑÌôò Ïã§Ìå®, ÏßÅÏ†ë Ï†ëÍ∑º ÏãúÎèÑ")
            
            # Ïó¨Îü¨ ÏÑ†ÌÉùÏûê ÏãúÎèÑ (ÎÑ§Ïù¥Î≤Ñ Ïπ¥Ìéò Íµ¨Ï°∞Í∞Ä Îã§ÏñëÌï®)
            selectors = [
                'div.article-board table tbody tr',  # Íµ¨Ìòï Ïπ¥Ìéò
                'ul.article-movie-sub li',  # ÏòÅÌôîÌòï
                'div.ArticleListItem',  # ÏÉàÌòï Ïπ¥Ìéò
                'tr[class*="board-list"]',  # ÏùºÎ∞ò Î¶¨Ïä§Ìä∏
                'div.inner_list > a'  # Î™®Î∞îÏùºÌòï
            ]
            
            articles = []
            for selector in selectors:
                try:
                    articles = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if articles:
                        logging.info(f"‚úÖ Í≤åÏãúÎ¨º Î∞úÍ≤¨: {selector} ({len(articles)}Í∞ú)")
                        break
                except:
                    continue
            
            if not articles:
                logging.warning("‚ùå Í≤åÏãúÎ¨ºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. HTML Íµ¨Ï°∞ ÌôïÏù∏ ÌïÑÏöî")
                # HTML ÎîîÎ≤ÑÍπÖ Ï†ïÎ≥¥
                try:
                    page_source = self.driver.page_source[:500]
                    logging.debug(f"Page HTML: {page_source}")
                except:
                    pass
                return results
            
            # Ïã§Ï†ú Í≤åÏãúÎ¨ºÎßå ÌïÑÌÑ∞ÎßÅ (Í≥µÏßÄÏÇ¨Ìï≠ Ï†úÏô∏)
            actual_articles = []
            for article in articles:
                try:
                    # Í≥µÏßÄÏÇ¨Ìï≠ ÌÅ¥ÎûòÏä§ Ï≤¥ÌÅ¨
                    class_attr = article.get_attribute('class') or ''
                    if 'notice' in class_attr.lower() or 'Í≥µÏßÄ' in class_attr:
                        continue
                    actual_articles.append(article)
                except:
                    actual_articles.append(article)
            
            logging.info(f"üìä Í≥µÏßÄ Ï†úÏô∏ Ïã§Ï†ú Í≤åÏãúÎ¨º: {len(actual_articles)}Í∞ú")
            
            # ÏµúÎåÄ 4Í∞úÏî©Îßå Ï≤òÎ¶¨
            max_articles = 4
            processed_count = 0
            
            for idx, article in enumerate(actual_articles[:10], 1):  # ÏµúÏã† 10Í∞ú Ï§ëÏóêÏÑú
                if processed_count >= max_articles:
                    logging.info(f"‚úÖ ÏµúÎåÄ Ï≤òÎ¶¨ Í∞úÏàò({max_articles}Í∞ú) ÎèÑÎã¨")
                    break
                    
                try:
                    logging.debug(f"Ï≤òÎ¶¨ Ï§ë: {processed_count + 1}/{max_articles}")
                    
                    # Ï†úÎ™© Ï∞æÍ∏∞ (Ïó¨Îü¨ Î∞©Î≤ï ÏãúÎèÑ)
                    title = ""
                    link = ""
                    
                    # Î∞©Î≤ï 1: a.article
                    try:
                        title_elem = article.find_element(By.CSS_SELECTOR, 'a.article')
                        title = title_elem.text.strip()
                        link = title_elem.get_attribute('href')
                    except:
                        pass
                    
                    # Î∞©Î≤ï 2: td.td_article
                    if not title:
                        try:
                            title_elem = article.find_element(By.CSS_SELECTOR, 'td.td_article a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            pass
                    
                    # Î∞©Î≤ï 3: class="inner_list"
                    if not title:
                        try:
                            title_elem = article.find_element(By.CSS_SELECTOR, '.inner_list a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            pass
                    
                    # Î∞©Î≤ï 4: ÏßÅÏ†ë a ÌÉúÍ∑∏
                    if not title:
                        try:
                            title_elem = article.find_element(By.TAG_NAME, 'a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                        except:
                            continue
                    
                    if not title or not link:
                        continue
                    
                    # Í≥µÏßÄÏÇ¨Ìï≠ Ï†úÏô∏
                    if 'Í≥µÏßÄ' in title or 'notice' in str(article.get_attribute('class')):
                        continue
                    
                    # ÏûëÏÑ±Ïûê
                    author = "Unknown"
                    for author_selector in ['td.td_name a', '.td_name', '.nick', '.p-nick']:
                        try:
                            author = article.find_element(By.CSS_SELECTOR, author_selector).text.strip()
                            if author:
                                break
                        except:
                            pass
                    
                    # ÏûëÏÑ±Ïùº
                    date_str = ""
                    for date_selector in ['td.td_date', '.td_date', '.date']:
                        try:
                            date_str = article.find_element(By.CSS_SELECTOR, date_selector).text.strip()
                            if date_str:
                                break
                        except:
                            pass
                    
                    # ÎÇ†Ïßú ÌòïÏãù Î≥ÄÌôò (YYYY.MM.DD. ‚Üí YYYY-MM-DD)
                    if date_str:
                        # "2025.08.25." ÌòïÏãùÏùÑ "2025-08-25"Î°ú Î≥ÄÌôò
                        date_str = date_str.replace('.', '-').rstrip('-')
                        if len(date_str.split('-')) == 3:
                            year, month, day = date_str.split('-')
                            # 2ÏûêÎ¶¨ Ïó∞ÎèÑ Ï≤òÎ¶¨
                            if len(year) == 2:
                                year = '20' + year
                            date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                        else:
                            date = datetime.now().strftime('%Y-%m-%d')
                    else:
                        date = datetime.now().strftime('%Y-%m-%d')
                    
                    # Ï°∞ÌöåÏàò
                    views = "0"
                    for view_selector in ['td.td_view', '.td_view', '.view']:
                        try:
                            views = article.find_element(By.CSS_SELECTOR, view_selector).text.strip()
                            if views:
                                break
                        except:
                            pass
                    
                    # Í≤åÏãúÎ¨º ID Ï∂îÏ∂ú
                    article_id = link.split('articleid=')[-1].split('&')[0] if 'articleid=' in link else ""
                    
                    # URLÎ°ú Ï§ëÎ≥µ Ï≤¥ÌÅ¨ (ÌÅ¨Î°§ÎßÅ Ï†ÑÏóê ÌôïÏù∏)
                    if link:
                        # Ïù¥ÎØ∏ ÎÖ∏ÏÖòÏóê ÏûàÎäîÏßÄ Î®ºÏ†Ä Ï≤¥ÌÅ¨
                        try:
                            notion_check = NotionDatabase()
                            if notion_check.check_duplicate(link):
                                logging.info(f"‚è≠Ô∏è Ïù¥ÎØ∏ Ï†ÄÏû•Îêú Í≤åÏãúÎ¨º: {title[:30]}...")
                                continue
                        except:
                            pass
                    
                    # ÏÉÅÏÑ∏ ÎÇ¥Ïö© ÌÅ¨Î°§ÎßÅ
                    content = self.get_article_content(link)
                    
                    # Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ±
                    data = {
                        'title': title,
                        'author': author,
                        'date': date,
                        'views': views,
                        'url': link,
                        'article_id': article_id,
                        'content': content,
                        'cafe_name': cafe_config['name'],
                        'board_name': cafe_config['board_name'],
                        'crawled_at': datetime.now().isoformat(),
                        'hash': hashlib.md5(f"{title}{link}".encode()).hexdigest()
                    }
                    
                    results.append(data)
                    processed_count += 1
                    logging.info(f"üìÑ [{processed_count:02d}/{max_articles}] ÌÅ¨Î°§ÎßÅ: {title[:30]}...")
                    
                    # ÏöîÏ≤≠ Í∞ÑÍ≤©
                    time.sleep(1)
                    
                except Exception as e:
                    logging.error(f"Í≤åÏãúÎ¨º ÌÅ¨Î°§ÎßÅ Ïò§Î•ò: {e}")
                    continue
            
            self.driver.switch_to.default_content()
            
        except Exception as e:
            logging.error(f"Ïπ¥Ìéò ÌÅ¨Î°§ÎßÅ Ïò§Î•ò: {e}")
        
        return results
    
    def get_article_content(self, url: str) -> str:
        """Í≤åÏãúÎ¨º ÏÉÅÏÑ∏ ÎÇ¥Ïö© Í∞ÄÏ†∏Ïò§Í∏∞"""
        try:
            # ÏÉà ÌÉ≠ÏóêÏÑú Ïó¥Í∏∞
            self.driver.execute_script(f"window.open('{url}', '_blank');")
            self.driver.switch_to.window(self.driver.window_handles[-1])
            time.sleep(2)
            
            # iframe Ï†ÑÌôò
            self.driver.switch_to.frame('cafe_main')
            
            # Î≥∏Î¨∏ ÎÇ¥Ïö© Ï∂îÏ∂ú
            content = ""
            try:
                content_elem = self.driver.find_element(By.CSS_SELECTOR, 'div.se-main-container, div.content-box')
                content = content_elem.text.strip()
            except:
                try:
                    content_elem = self.driver.find_element(By.CSS_SELECTOR, 'div#tbody')
                    content = content_elem.text.strip()
                except:
                    content = ""
            
            # ÌÉ≠ Îã´Í∏∞
            self.driver.close()
            self.driver.switch_to.window(self.driver.window_handles[0])
            
            return content[:2000]  # ÎÖ∏ÏÖò Ï†úÌïú
            
        except Exception as e:
            logging.error(f"ÎÇ¥Ïö© Ï∂îÏ∂ú Ïò§Î•ò: {e}")
            return ""
    
    def close(self):
        """ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å"""
        if self.driver:
            self.driver.quit()
            logging.info("‚úÖ ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å")


class NotionDatabase:
    """ÎÖ∏ÏÖò Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ìï∏Îì§Îü¨"""
    
    def __init__(self):
        self.client = Client(auth=os.getenv('NOTION_TOKEN'))
        self.database_id = os.getenv('NOTION_DATABASE_ID')
    
    def check_duplicate(self, hash_value: str) -> bool:
        """Ï§ëÎ≥µ Ï≤¥ÌÅ¨"""
        try:
            # Ìï¥Ïãú ÌïÑÎìúÍ∞Ä ÏóÜÏùÑ ÏàòÎèÑ ÏûàÏúºÎØÄÎ°ú URLÎ°ú Ï§ëÎ≥µ Ï≤¥ÌÅ¨
            response = self.client.databases.query(
                database_id=self.database_id,
                filter={
                    "or": [
                        {
                            "property": "URL",
                            "url": {
                                "contains": hash_value[:20]  # URL ÏùºÎ∂ÄÎ°ú Ï≤¥ÌÅ¨
                            }
                        }
                    ]
                }
            )
            return len(response['results']) > 0
        except Exception as e:
            logging.debug(f"Ï§ëÎ≥µ Ï≤¥ÌÅ¨ Ïã§Ìå®: {e}")
            return False
    
    def save_article(self, article: Dict) -> bool:
        """Í≤åÏãúÎ¨º Ï†ÄÏû•"""
        try:
            # URLÎ°ú Ï§ëÎ≥µ Ï≤¥ÌÅ¨
            if self.check_duplicate(article['url']):
                logging.info(f"‚è≠Ô∏è Ï§ëÎ≥µ Í≤åÏãúÎ¨º Í±¥ÎÑàÎõ∞Í∏∞: {article['title'][:30]}...")
                return False
            
            # ÎÖ∏ÏÖò DBÏùò Ïã§Ï†ú ÌïÑÎìúÏóê ÎßûÏ∂∞ÏÑú Ï†ÄÏû•
            properties = {
                "ÌïòÏúóÌä∏ Ïñ¥ÏõåÎìú ÌåêÎß§(Ïä§ÏúÑÌä∏,Goh,ÌÅ¥ÎüΩ)": {  # Ï†úÎ™© ÌïÑÎìú
                    "title": [{"text": {"content": article['title']}}]
                },
                "URL": {
                    "url": article['url']
                }
            }
            
            # ÏÑ†ÌÉùÏ†Å ÌïÑÎìúÎì§ (ÏûàÏúºÎ©¥ Ï∂îÍ∞Ä)
            if article.get('author'):
                properties["ÏûëÏÑ±Ïûê"] = {
                    "rich_text": [{"text": {"content": article['author']}}]
                }
            
            if article.get('date'):
                properties["ÏûëÏÑ±Ïùº"] = {
                    "date": {"start": article['date']}
                }
            
            if article.get('cafe_name'):
                properties["Ïπ¥ÌéòÎ™Ö"] = {
                    "select": {"name": article['cafe_name']}
                }
            
            # ÎÇ¥Ïö© ÌïÑÎìú Ï≤òÎ¶¨
            content = article.get('content', '')[:2000]
            if content:
                properties["ÎÇ¥Ïö©"] = {
                    "rich_text": [{"text": {"content": content}}]
                }
            
            # ÌÅ¨Î°§ÎßÅ ÏùºÏãú
            properties["ÌÅ¨Î°§ÎßÅ ÏùºÏãú"] = {
                "date": {"start": datetime.now().isoformat()}
            }
            
            # uploaded Ï≤¥ÌÅ¨Î∞ïÏä§
            properties["uploaded"] = {
                "checkbox": False
            }
            
            # ÎÖ∏ÏÖò ÌéòÏù¥ÏßÄ ÏÉùÏÑ±
            page = self.client.pages.create(
                parent={"database_id": self.database_id},
                properties=properties
            )
            
            logging.info(f"‚úÖ ÎÖ∏ÏÖò Ï†ÄÏû• ÏÑ±Í≥µ: {article['title'][:30]}...")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå ÎÖ∏ÏÖò Ï†ÄÏû• Ïã§Ìå®: {e}")
            return False


def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    logging.info("="*60)
    logging.info("üöÄ ÎÑ§Ïù¥Î≤Ñ Ïπ¥Ìéò -> ÎÖ∏ÏÖò ÌÅ¨Î°§ÎßÅ ÏãúÏûë")
    logging.info(f"‚è∞ Ïã§Ìñâ ÏãúÍ∞Ñ: {datetime.now()}")
    logging.info("="*60)
    
    # ÌôòÍ≤ΩÎ≥ÄÏàò ÌôïÏù∏
    required_env = ['NAVER_ID', 'NAVER_PW', 'NOTION_TOKEN', 'NOTION_DATABASE_ID']
    missing_env = [env for env in required_env if not os.getenv(env)]
    
    if missing_env:
        logging.error(f"‚ùå ÌïÑÏàò ÌôòÍ≤ΩÎ≥ÄÏàòÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§: {', '.join(missing_env)}")
        logging.error("GitHub SecretsÎ•º ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî!")
        sys.exit(1)
    
    # Ïπ¥Ìéò ÏÑ§Ï†ï (2Í≥≥)
    cafes = []
    
    # Ïπ¥Ìéò 1 ÏÑ§Ï†ï ÌôïÏù∏
    if os.getenv('CAFE1_URL') and os.getenv('CAFE1_CLUB_ID') and os.getenv('CAFE1_BOARD_ID'):
        cafes.append({
            'name': os.getenv('CAFE1_NAME', 'Ïπ¥Ìéò1'),
            'url': os.getenv('CAFE1_URL'),
            'club_id': os.getenv('CAFE1_CLUB_ID'),
            'board_id': os.getenv('CAFE1_BOARD_ID'),
            'board_name': os.getenv('CAFE1_BOARD_NAME', 'Í≤åÏãúÌåê')
        })
    
    # Ïπ¥Ìéò 2 ÏÑ§Ï†ï ÌôïÏù∏
    if os.getenv('CAFE2_URL') and os.getenv('CAFE2_CLUB_ID') and os.getenv('CAFE2_BOARD_ID'):
        cafes.append({
            'name': os.getenv('CAFE2_NAME', 'Ïπ¥Ìéò2'),
            'url': os.getenv('CAFE2_URL'),
            'club_id': os.getenv('CAFE2_CLUB_ID'),
            'board_id': os.getenv('CAFE2_BOARD_ID'),
            'board_name': os.getenv('CAFE2_BOARD_NAME', 'Í≤åÏãúÌåê')
        })
    
    if not cafes:
        logging.error("‚ùå ÌÅ¨Î°§ÎßÅÌï† Ïπ¥ÌéòÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§!")
        logging.error("ÏµúÏÜå 1Í∞ú Ïù¥ÏÉÅÏùò Ïπ¥Ìéò Ï†ïÎ≥¥Î•º GitHub SecretsÏóê ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî:")
        logging.error("CAFE1_URL, CAFE1_CLUB_ID, CAFE1_BOARD_ID")
        sys.exit(1)
    
    # ÌÅ¨Î°§Îü¨ Ï¥àÍ∏∞Ìôî
    crawler = NaverCafeCrawler()
    notion = NotionDatabase()
    
    try:
        # ÎÑ§Ïù¥Î≤Ñ Î°úÍ∑∏Ïù∏
        if not crawler.login_naver():
            raise Exception("Î°úÍ∑∏Ïù∏ Ïã§Ìå®")
        
        total_saved = 0
        
        # Í∞Å Ïπ¥Ìéò ÌÅ¨Î°§ÎßÅ
        for cafe in cafes:
            logging.info(f"\nüìç {cafe['name']} ÌÅ¨Î°§ÎßÅ ÏãúÏûë...")
            articles = crawler.crawl_cafe(cafe)
            
            # ÎÖ∏ÏÖòÏóê Ï†ÄÏû•
            cafe_saved = 0
            for article in articles:
                if notion.save_article(article):
                    cafe_saved += 1
                    total_saved += 1
            
            logging.info(f"‚úÖ {cafe['name']}: {len(articles)}Í∞ú ÌÅ¨Î°§ÎßÅ, {cafe_saved}Í∞ú ÏÉàÎ°ú Ï†ÄÏû•")
            time.sleep(2)
        
        logging.info(f"\nüéâ ÌÅ¨Î°§ÎßÅ ÏôÑÎ£å! Ï¥ù {total_saved}Í∞ú ÏÉà Í≤åÏãúÎ¨º Ï†ÄÏû•")
        
    except Exception as e:
        logging.error(f"‚ùå ÌÅ¨Î°§ÎßÅ Ïã§Ìå®: {e}")
        sys.exit(1)
    
    finally:
        crawler.close()


if __name__ == "__main__":
    main()